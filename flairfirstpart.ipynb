{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73faf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c541d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:52:16,623 Reading data from data\n",
      "2022-01-04 16:52:16,624 Train: data\\flairfirspart.txt\n",
      "2022-01-04 16:52:16,625 Dev: data\\flairval2.txt\n",
      "2022-01-04 16:52:16,627 Test: data\\flairtest2.txt\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "corpus: Corpus = ColumnCorpus('data/', columns,\n",
    "                              train_file='flairfirspart.txt',\n",
    "                              test_file='flairtest2.txt',\n",
    "                              dev_file='flairval2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ee98d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:52:18,044 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3173/3173 [00:00<00:00, 11332.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:52:18,328 Corpus contains the labels: ner (#75237)\n",
      "2022-01-04 16:52:18,329 Created (for label 'ner') Dictionary with 7 tags: <unk>, O, -, U-PERSON, B-PERSON, L-PERSON, I-PERSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tag to predict\n",
    "tag_type = 'ner'# make tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_label_dictionary(tag_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1acdd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, TokenEmbeddings\n",
    "from typing import List\n",
    "embedding_types : List[TokenEmbeddings] = [\n",
    "        WordEmbeddings('glove'),\n",
    "        ## other embeddings\n",
    "        ]\n",
    "embeddings : StackedEmbeddings = StackedEmbeddings(\n",
    "                                 embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cabfa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=9, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                       embeddings=embeddings,\n",
    "                                       tag_dictionary=tag_dictionary,\n",
    "                                       tag_type=tag_type,\n",
    "                                       use_crf=True)\n",
    "print(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17b8912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:52:33,039 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:52:33,041 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=9, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-01-04 16:52:33,042 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:52:33,044 Corpus: \"Corpus: 3173 train + 546 dev + 438 test sentences\"\n",
      "2022-01-04 16:52:33,045 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:52:33,047 Parameters:\n",
      "2022-01-04 16:52:33,048  - learning_rate: \"0.1\"\n",
      "2022-01-04 16:52:33,049  - mini_batch_size: \"32\"\n",
      "2022-01-04 16:52:33,050  - patience: \"3\"\n",
      "2022-01-04 16:52:33,051  - anneal_factor: \"0.5\"\n",
      "2022-01-04 16:52:33,052  - max_epochs: \"150\"\n",
      "2022-01-04 16:52:33,053  - shuffle: \"True\"\n",
      "2022-01-04 16:52:33,054  - train_with_dev: \"False\"\n",
      "2022-01-04 16:52:33,055  - batch_growth_annealing: \"False\"\n",
      "2022-01-04 16:52:33,056 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:52:33,057 Model training base path: \"data\\flairfirstpartmodel\"\n",
      "2022-01-04 16:52:33,058 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:52:33,059 Device: cpu\n",
      "2022-01-04 16:52:33,060 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:52:33,061 Embeddings storage mode: cpu\n",
      "2022-01-04 16:52:33,066 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:52:40,887 epoch 1 - iter 10/100 - loss 0.55064136 - samples/sec: 40.94 - lr: 0.100000\n",
      "2022-01-04 16:52:48,413 epoch 1 - iter 20/100 - loss 0.30947183 - samples/sec: 42.54 - lr: 0.100000\n",
      "2022-01-04 16:52:57,393 epoch 1 - iter 30/100 - loss 0.22101348 - samples/sec: 35.64 - lr: 0.100000\n",
      "2022-01-04 16:53:04,347 epoch 1 - iter 40/100 - loss 0.18061726 - samples/sec: 46.04 - lr: 0.100000\n",
      "2022-01-04 16:53:12,251 epoch 1 - iter 50/100 - loss 0.15332022 - samples/sec: 40.50 - lr: 0.100000\n",
      "2022-01-04 16:53:19,549 epoch 1 - iter 60/100 - loss 0.13529038 - samples/sec: 43.87 - lr: 0.100000\n",
      "2022-01-04 16:53:28,736 epoch 1 - iter 70/100 - loss 0.12070729 - samples/sec: 34.84 - lr: 0.100000\n",
      "2022-01-04 16:53:37,338 epoch 1 - iter 80/100 - loss 0.11109868 - samples/sec: 37.21 - lr: 0.100000\n",
      "2022-01-04 16:53:44,301 epoch 1 - iter 90/100 - loss 0.10416824 - samples/sec: 45.98 - lr: 0.100000\n",
      "2022-01-04 16:53:51,973 epoch 1 - iter 100/100 - loss 0.09811137 - samples/sec: 41.73 - lr: 0.100000\n",
      "2022-01-04 16:53:51,974 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:53:51,975 EPOCH 1 done: loss 0.0981 - lr 0.1000000\n",
      "2022-01-04 16:53:54,867 DEV : loss 0.031845755875110626 - f1-score (micro avg)  0.4813\n",
      "2022-01-04 16:53:54,909 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 16:53:54,911 saving best model\n",
      "2022-01-04 16:54:00,109 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:54:07,814 epoch 2 - iter 10/100 - loss 0.04506503 - samples/sec: 41.59 - lr: 0.100000\n",
      "2022-01-04 16:54:15,193 epoch 2 - iter 20/100 - loss 0.03304347 - samples/sec: 43.40 - lr: 0.100000\n",
      "2022-01-04 16:54:22,056 epoch 2 - iter 30/100 - loss 0.03465848 - samples/sec: 46.64 - lr: 0.100000\n",
      "2022-01-04 16:54:29,901 epoch 2 - iter 40/100 - loss 0.03801056 - samples/sec: 40.80 - lr: 0.100000\n",
      "2022-01-04 16:54:37,804 epoch 2 - iter 50/100 - loss 0.03709398 - samples/sec: 40.50 - lr: 0.100000\n",
      "2022-01-04 16:54:45,714 epoch 2 - iter 60/100 - loss 0.03578455 - samples/sec: 40.47 - lr: 0.100000\n",
      "2022-01-04 16:54:52,732 epoch 2 - iter 70/100 - loss 0.03505599 - samples/sec: 45.61 - lr: 0.100000\n",
      "2022-01-04 16:54:59,803 epoch 2 - iter 80/100 - loss 0.03549111 - samples/sec: 45.27 - lr: 0.100000\n",
      "2022-01-04 16:55:07,823 epoch 2 - iter 90/100 - loss 0.03525230 - samples/sec: 39.91 - lr: 0.100000\n",
      "2022-01-04 16:55:14,485 epoch 2 - iter 100/100 - loss 0.03487915 - samples/sec: 48.04 - lr: 0.100000\n",
      "2022-01-04 16:55:14,486 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:55:14,487 EPOCH 2 done: loss 0.0349 - lr 0.1000000\n",
      "2022-01-04 16:55:16,720 DEV : loss 0.022621553391218185 - f1-score (micro avg)  0.7474\n",
      "2022-01-04 16:55:16,752 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 16:55:16,753 saving best model\n",
      "2022-01-04 16:55:18,444 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:55:26,488 epoch 3 - iter 10/100 - loss 0.01947278 - samples/sec: 39.80 - lr: 0.100000\n",
      "2022-01-04 16:55:33,153 epoch 3 - iter 20/100 - loss 0.02745736 - samples/sec: 48.03 - lr: 0.100000\n",
      "2022-01-04 16:55:41,202 epoch 3 - iter 30/100 - loss 0.03139811 - samples/sec: 39.77 - lr: 0.100000\n",
      "2022-01-04 16:55:48,784 epoch 3 - iter 40/100 - loss 0.02820911 - samples/sec: 42.23 - lr: 0.100000\n",
      "2022-01-04 16:55:56,602 epoch 3 - iter 50/100 - loss 0.03116837 - samples/sec: 40.96 - lr: 0.100000\n",
      "2022-01-04 16:56:02,974 epoch 3 - iter 60/100 - loss 0.03225458 - samples/sec: 50.24 - lr: 0.100000\n",
      "2022-01-04 16:56:10,099 epoch 3 - iter 70/100 - loss 0.03191121 - samples/sec: 44.94 - lr: 0.100000\n",
      "2022-01-04 16:56:18,047 epoch 3 - iter 80/100 - loss 0.03148724 - samples/sec: 40.28 - lr: 0.100000\n",
      "2022-01-04 16:56:25,364 epoch 3 - iter 90/100 - loss 0.03153045 - samples/sec: 43.74 - lr: 0.100000\n",
      "2022-01-04 16:56:34,623 epoch 3 - iter 100/100 - loss 0.03125785 - samples/sec: 34.58 - lr: 0.100000\n",
      "2022-01-04 16:56:34,624 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:56:34,625 EPOCH 3 done: loss 0.0313 - lr 0.1000000\n",
      "2022-01-04 16:56:37,407 DEV : loss 0.029226049780845642 - f1-score (micro avg)  0.609\n",
      "2022-01-04 16:56:37,459 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 16:56:37,460 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:56:44,640 epoch 4 - iter 10/100 - loss 0.03054813 - samples/sec: 44.61 - lr: 0.100000\n",
      "2022-01-04 16:56:52,068 epoch 4 - iter 20/100 - loss 0.03221154 - samples/sec: 43.10 - lr: 0.100000\n",
      "2022-01-04 16:56:59,717 epoch 4 - iter 30/100 - loss 0.03195905 - samples/sec: 41.86 - lr: 0.100000\n",
      "2022-01-04 16:57:08,046 epoch 4 - iter 40/100 - loss 0.02967580 - samples/sec: 38.44 - lr: 0.100000\n",
      "2022-01-04 16:57:16,112 epoch 4 - iter 50/100 - loss 0.03000926 - samples/sec: 39.68 - lr: 0.100000\n",
      "2022-01-04 16:57:23,358 epoch 4 - iter 60/100 - loss 0.02880416 - samples/sec: 44.18 - lr: 0.100000\n",
      "2022-01-04 16:57:30,945 epoch 4 - iter 70/100 - loss 0.02866991 - samples/sec: 42.19 - lr: 0.100000\n",
      "2022-01-04 16:57:38,118 epoch 4 - iter 80/100 - loss 0.02969587 - samples/sec: 44.62 - lr: 0.100000\n",
      "2022-01-04 16:57:45,011 epoch 4 - iter 90/100 - loss 0.02941041 - samples/sec: 46.43 - lr: 0.100000\n",
      "2022-01-04 16:57:52,735 epoch 4 - iter 100/100 - loss 0.02946941 - samples/sec: 41.44 - lr: 0.100000\n",
      "2022-01-04 16:57:52,737 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:57:52,738 EPOCH 4 done: loss 0.0295 - lr 0.1000000\n",
      "2022-01-04 16:57:55,131 DEV : loss 0.01583755575120449 - f1-score (micro avg)  0.8\n",
      "2022-01-04 16:57:55,167 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 16:57:55,169 saving best model\n",
      "2022-01-04 16:57:56,875 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:58:03,987 epoch 5 - iter 10/100 - loss 0.02792840 - samples/sec: 45.01 - lr: 0.100000\n",
      "2022-01-04 16:58:11,935 epoch 5 - iter 20/100 - loss 0.02944737 - samples/sec: 40.28 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:58:19,224 epoch 5 - iter 30/100 - loss 0.02583411 - samples/sec: 43.91 - lr: 0.100000\n",
      "2022-01-04 16:58:26,520 epoch 5 - iter 40/100 - loss 0.02617781 - samples/sec: 43.88 - lr: 0.100000\n",
      "2022-01-04 16:58:35,538 epoch 5 - iter 50/100 - loss 0.02410762 - samples/sec: 35.49 - lr: 0.100000\n",
      "2022-01-04 16:58:41,995 epoch 5 - iter 60/100 - loss 0.02619052 - samples/sec: 49.57 - lr: 0.100000\n",
      "2022-01-04 16:58:48,731 epoch 5 - iter 70/100 - loss 0.02647626 - samples/sec: 47.51 - lr: 0.100000\n",
      "2022-01-04 16:58:56,501 epoch 5 - iter 80/100 - loss 0.02686866 - samples/sec: 41.20 - lr: 0.100000\n",
      "2022-01-04 16:59:04,077 epoch 5 - iter 90/100 - loss 0.02771354 - samples/sec: 42.26 - lr: 0.100000\n",
      "2022-01-04 16:59:10,975 epoch 5 - iter 100/100 - loss 0.02721265 - samples/sec: 46.41 - lr: 0.100000\n",
      "2022-01-04 16:59:10,977 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:59:10,978 EPOCH 5 done: loss 0.0272 - lr 0.1000000\n",
      "2022-01-04 16:59:13,824 DEV : loss 0.015080180950462818 - f1-score (micro avg)  0.8\n",
      "2022-01-04 16:59:13,864 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 16:59:13,866 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 16:59:21,596 epoch 6 - iter 10/100 - loss 0.02374414 - samples/sec: 41.41 - lr: 0.100000\n",
      "2022-01-04 16:59:28,734 epoch 6 - iter 20/100 - loss 0.02618793 - samples/sec: 44.85 - lr: 0.100000\n",
      "2022-01-04 16:59:35,355 epoch 6 - iter 30/100 - loss 0.02718195 - samples/sec: 48.35 - lr: 0.100000\n",
      "2022-01-04 16:59:42,980 epoch 6 - iter 40/100 - loss 0.02430504 - samples/sec: 42.00 - lr: 0.100000\n",
      "2022-01-04 16:59:50,297 epoch 6 - iter 50/100 - loss 0.02521036 - samples/sec: 43.75 - lr: 0.100000\n",
      "2022-01-04 16:59:58,658 epoch 6 - iter 60/100 - loss 0.02581886 - samples/sec: 38.28 - lr: 0.100000\n",
      "2022-01-04 17:00:05,957 epoch 6 - iter 70/100 - loss 0.02599066 - samples/sec: 43.86 - lr: 0.100000\n",
      "2022-01-04 17:00:14,186 epoch 6 - iter 80/100 - loss 0.02566954 - samples/sec: 38.90 - lr: 0.100000\n",
      "2022-01-04 17:00:21,178 epoch 6 - iter 90/100 - loss 0.02599332 - samples/sec: 45.78 - lr: 0.100000\n",
      "2022-01-04 17:00:28,004 epoch 6 - iter 100/100 - loss 0.02485881 - samples/sec: 46.91 - lr: 0.100000\n",
      "2022-01-04 17:00:28,006 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:00:28,008 EPOCH 6 done: loss 0.0249 - lr 0.1000000\n",
      "2022-01-04 17:00:30,532 DEV : loss 0.013231400400400162 - f1-score (micro avg)  0.8606\n",
      "2022-01-04 17:00:30,576 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:00:30,578 saving best model\n",
      "2022-01-04 17:00:32,634 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:00:40,860 epoch 7 - iter 10/100 - loss 0.02201002 - samples/sec: 38.91 - lr: 0.100000\n",
      "2022-01-04 17:00:48,636 epoch 7 - iter 20/100 - loss 0.02072726 - samples/sec: 41.17 - lr: 0.100000\n",
      "2022-01-04 17:00:56,445 epoch 7 - iter 30/100 - loss 0.02081851 - samples/sec: 40.99 - lr: 0.100000\n",
      "2022-01-04 17:01:02,583 epoch 7 - iter 40/100 - loss 0.02229394 - samples/sec: 52.17 - lr: 0.100000\n",
      "2022-01-04 17:01:09,657 epoch 7 - iter 50/100 - loss 0.02229653 - samples/sec: 45.25 - lr: 0.100000\n",
      "2022-01-04 17:01:17,698 epoch 7 - iter 60/100 - loss 0.02356800 - samples/sec: 39.80 - lr: 0.100000\n",
      "2022-01-04 17:01:24,827 epoch 7 - iter 70/100 - loss 0.02438357 - samples/sec: 44.91 - lr: 0.100000\n",
      "2022-01-04 17:01:31,389 epoch 7 - iter 80/100 - loss 0.02616946 - samples/sec: 48.79 - lr: 0.100000\n",
      "2022-01-04 17:01:39,804 epoch 7 - iter 90/100 - loss 0.02669762 - samples/sec: 38.04 - lr: 0.100000\n",
      "2022-01-04 17:01:47,266 epoch 7 - iter 100/100 - loss 0.02555113 - samples/sec: 42.90 - lr: 0.100000\n",
      "2022-01-04 17:01:47,268 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:01:47,269 EPOCH 7 done: loss 0.0256 - lr 0.1000000\n",
      "2022-01-04 17:01:49,613 DEV : loss 0.011867337860167027 - f1-score (micro avg)  0.8819\n",
      "2022-01-04 17:01:49,657 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:01:49,660 saving best model\n",
      "2022-01-04 17:01:52,118 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:01:59,473 epoch 8 - iter 10/100 - loss 0.03038515 - samples/sec: 43.52 - lr: 0.100000\n",
      "2022-01-04 17:02:06,478 epoch 8 - iter 20/100 - loss 0.02936456 - samples/sec: 45.70 - lr: 0.100000\n",
      "2022-01-04 17:02:13,696 epoch 8 - iter 30/100 - loss 0.02693242 - samples/sec: 44.36 - lr: 0.100000\n",
      "2022-01-04 17:02:21,372 epoch 8 - iter 40/100 - loss 0.02473307 - samples/sec: 41.72 - lr: 0.100000\n",
      "2022-01-04 17:02:28,473 epoch 8 - iter 50/100 - loss 0.02473405 - samples/sec: 45.09 - lr: 0.100000\n",
      "2022-01-04 17:02:36,887 epoch 8 - iter 60/100 - loss 0.02502400 - samples/sec: 38.03 - lr: 0.100000\n",
      "2022-01-04 17:02:44,469 epoch 8 - iter 70/100 - loss 0.02444177 - samples/sec: 42.23 - lr: 0.100000\n",
      "2022-01-04 17:02:53,279 epoch 8 - iter 80/100 - loss 0.02495858 - samples/sec: 36.33 - lr: 0.100000\n",
      "2022-01-04 17:03:00,254 epoch 8 - iter 90/100 - loss 0.02453926 - samples/sec: 45.89 - lr: 0.100000\n",
      "2022-01-04 17:03:08,031 epoch 8 - iter 100/100 - loss 0.02441009 - samples/sec: 41.16 - lr: 0.100000\n",
      "2022-01-04 17:03:08,033 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:03:08,034 EPOCH 8 done: loss 0.0244 - lr 0.1000000\n",
      "2022-01-04 17:03:10,485 DEV : loss 0.014587203040719032 - f1-score (micro avg)  0.8535\n",
      "2022-01-04 17:03:10,517 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:03:10,519 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:03:17,771 epoch 9 - iter 10/100 - loss 0.02217294 - samples/sec: 44.16 - lr: 0.100000\n",
      "2022-01-04 17:03:26,119 epoch 9 - iter 20/100 - loss 0.01884261 - samples/sec: 38.35 - lr: 0.100000\n",
      "2022-01-04 17:03:33,281 epoch 9 - iter 30/100 - loss 0.02180859 - samples/sec: 44.70 - lr: 0.100000\n",
      "2022-01-04 17:03:40,161 epoch 9 - iter 40/100 - loss 0.02251769 - samples/sec: 46.52 - lr: 0.100000\n",
      "2022-01-04 17:03:47,535 epoch 9 - iter 50/100 - loss 0.02180527 - samples/sec: 43.41 - lr: 0.100000\n",
      "2022-01-04 17:03:54,843 epoch 9 - iter 60/100 - loss 0.02214279 - samples/sec: 43.79 - lr: 0.100000\n",
      "2022-01-04 17:04:02,345 epoch 9 - iter 70/100 - loss 0.02319141 - samples/sec: 42.68 - lr: 0.100000\n",
      "2022-01-04 17:04:10,558 epoch 9 - iter 80/100 - loss 0.02308480 - samples/sec: 38.99 - lr: 0.100000\n",
      "2022-01-04 17:04:18,661 epoch 9 - iter 90/100 - loss 0.02393804 - samples/sec: 39.50 - lr: 0.100000\n",
      "2022-01-04 17:04:25,772 epoch 9 - iter 100/100 - loss 0.02344458 - samples/sec: 45.02 - lr: 0.100000\n",
      "2022-01-04 17:04:25,773 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:04:25,774 EPOCH 9 done: loss 0.0234 - lr 0.1000000\n",
      "2022-01-04 17:04:28,102 DEV : loss 0.010480658151209354 - f1-score (micro avg)  0.9148\n",
      "2022-01-04 17:04:28,144 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:04:28,146 saving best model\n",
      "2022-01-04 17:04:29,838 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:04:38,178 epoch 10 - iter 10/100 - loss 0.02408991 - samples/sec: 38.38 - lr: 0.100000\n",
      "2022-01-04 17:04:44,948 epoch 10 - iter 20/100 - loss 0.02212833 - samples/sec: 47.28 - lr: 0.100000\n",
      "2022-01-04 17:04:53,163 epoch 10 - iter 30/100 - loss 0.02170151 - samples/sec: 38.97 - lr: 0.100000\n",
      "2022-01-04 17:05:00,514 epoch 10 - iter 40/100 - loss 0.01919745 - samples/sec: 43.56 - lr: 0.100000\n",
      "2022-01-04 17:05:08,559 epoch 10 - iter 50/100 - loss 0.02050741 - samples/sec: 39.79 - lr: 0.100000\n",
      "2022-01-04 17:05:16,177 epoch 10 - iter 60/100 - loss 0.02020170 - samples/sec: 42.02 - lr: 0.100000\n",
      "2022-01-04 17:05:22,681 epoch 10 - iter 70/100 - loss 0.02110769 - samples/sec: 49.22 - lr: 0.100000\n",
      "2022-01-04 17:05:29,157 epoch 10 - iter 80/100 - loss 0.02147737 - samples/sec: 49.44 - lr: 0.100000\n",
      "2022-01-04 17:05:38,347 epoch 10 - iter 90/100 - loss 0.02141503 - samples/sec: 34.83 - lr: 0.100000\n",
      "2022-01-04 17:05:46,323 epoch 10 - iter 100/100 - loss 0.02243989 - samples/sec: 40.14 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:05:46,325 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:05:46,326 EPOCH 10 done: loss 0.0224 - lr 0.1000000\n",
      "2022-01-04 17:05:49,571 DEV : loss 0.0187847763299942 - f1-score (micro avg)  0.6763\n",
      "2022-01-04 17:05:49,611 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:05:49,613 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:05:57,882 epoch 11 - iter 10/100 - loss 0.02683501 - samples/sec: 38.72 - lr: 0.100000\n",
      "2022-01-04 17:06:05,357 epoch 11 - iter 20/100 - loss 0.02592722 - samples/sec: 42.82 - lr: 0.100000\n",
      "2022-01-04 17:06:12,606 epoch 11 - iter 30/100 - loss 0.02465658 - samples/sec: 44.15 - lr: 0.100000\n",
      "2022-01-04 17:06:20,216 epoch 11 - iter 40/100 - loss 0.02657129 - samples/sec: 42.06 - lr: 0.100000\n",
      "2022-01-04 17:06:27,466 epoch 11 - iter 50/100 - loss 0.02622253 - samples/sec: 44.14 - lr: 0.100000\n",
      "2022-01-04 17:06:34,393 epoch 11 - iter 60/100 - loss 0.02437571 - samples/sec: 46.22 - lr: 0.100000\n",
      "2022-01-04 17:06:42,029 epoch 11 - iter 70/100 - loss 0.02386966 - samples/sec: 41.91 - lr: 0.100000\n",
      "2022-01-04 17:06:50,658 epoch 11 - iter 80/100 - loss 0.02365584 - samples/sec: 37.11 - lr: 0.100000\n",
      "2022-01-04 17:06:58,228 epoch 11 - iter 90/100 - loss 0.02295449 - samples/sec: 42.29 - lr: 0.100000\n",
      "2022-01-04 17:07:05,022 epoch 11 - iter 100/100 - loss 0.02322899 - samples/sec: 47.12 - lr: 0.100000\n",
      "2022-01-04 17:07:05,024 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:07:05,025 EPOCH 11 done: loss 0.0232 - lr 0.1000000\n",
      "2022-01-04 17:07:07,399 DEV : loss 0.009429638274013996 - f1-score (micro avg)  0.9113\n",
      "2022-01-04 17:07:07,445 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:07:07,446 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:07:15,012 epoch 12 - iter 10/100 - loss 0.01353886 - samples/sec: 42.31 - lr: 0.100000\n",
      "2022-01-04 17:07:23,324 epoch 12 - iter 20/100 - loss 0.01609571 - samples/sec: 38.51 - lr: 0.100000\n",
      "2022-01-04 17:07:30,935 epoch 12 - iter 30/100 - loss 0.02113471 - samples/sec: 42.06 - lr: 0.100000\n",
      "2022-01-04 17:07:38,993 epoch 12 - iter 40/100 - loss 0.02383726 - samples/sec: 39.74 - lr: 0.100000\n",
      "2022-01-04 17:07:46,919 epoch 12 - iter 50/100 - loss 0.02366628 - samples/sec: 40.38 - lr: 0.100000\n",
      "2022-01-04 17:07:53,534 epoch 12 - iter 60/100 - loss 0.02213184 - samples/sec: 48.39 - lr: 0.100000\n",
      "2022-01-04 17:08:01,804 epoch 12 - iter 70/100 - loss 0.02269739 - samples/sec: 38.71 - lr: 0.100000\n",
      "2022-01-04 17:08:08,074 epoch 12 - iter 80/100 - loss 0.02205029 - samples/sec: 51.05 - lr: 0.100000\n",
      "2022-01-04 17:08:15,873 epoch 12 - iter 90/100 - loss 0.02208543 - samples/sec: 41.04 - lr: 0.100000\n",
      "2022-01-04 17:08:22,753 epoch 12 - iter 100/100 - loss 0.02229850 - samples/sec: 46.54 - lr: 0.100000\n",
      "2022-01-04 17:08:22,755 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:08:22,755 EPOCH 12 done: loss 0.0223 - lr 0.1000000\n",
      "2022-01-04 17:08:25,177 DEV : loss 0.011948765255510807 - f1-score (micro avg)  0.8342\n",
      "2022-01-04 17:08:25,219 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:08:25,221 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:08:33,002 epoch 13 - iter 10/100 - loss 0.03228524 - samples/sec: 41.15 - lr: 0.100000\n",
      "2022-01-04 17:08:39,629 epoch 13 - iter 20/100 - loss 0.02484848 - samples/sec: 48.29 - lr: 0.100000\n",
      "2022-01-04 17:08:46,544 epoch 13 - iter 30/100 - loss 0.02247859 - samples/sec: 46.30 - lr: 0.100000\n",
      "2022-01-04 17:08:54,037 epoch 13 - iter 40/100 - loss 0.02325229 - samples/sec: 42.72 - lr: 0.100000\n",
      "2022-01-04 17:09:01,374 epoch 13 - iter 50/100 - loss 0.02241669 - samples/sec: 43.64 - lr: 0.100000\n",
      "2022-01-04 17:09:09,341 epoch 13 - iter 60/100 - loss 0.02211292 - samples/sec: 40.17 - lr: 0.100000\n",
      "2022-01-04 17:09:16,987 epoch 13 - iter 70/100 - loss 0.02314858 - samples/sec: 41.87 - lr: 0.100000\n",
      "2022-01-04 17:09:24,743 epoch 13 - iter 80/100 - loss 0.02190317 - samples/sec: 41.28 - lr: 0.100000\n",
      "2022-01-04 17:09:33,202 epoch 13 - iter 90/100 - loss 0.02218270 - samples/sec: 37.85 - lr: 0.100000\n",
      "2022-01-04 17:09:40,676 epoch 13 - iter 100/100 - loss 0.02186664 - samples/sec: 42.83 - lr: 0.100000\n",
      "2022-01-04 17:09:40,677 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:09:40,678 EPOCH 13 done: loss 0.0219 - lr 0.1000000\n",
      "2022-01-04 17:09:43,090 DEV : loss 0.01105648186057806 - f1-score (micro avg)  0.8834\n",
      "Epoch    13: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2022-01-04 17:09:43,120 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:09:43,123 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:09:50,211 epoch 14 - iter 10/100 - loss 0.01725991 - samples/sec: 45.16 - lr: 0.050000\n",
      "2022-01-04 17:09:57,046 epoch 14 - iter 20/100 - loss 0.01504952 - samples/sec: 46.82 - lr: 0.050000\n",
      "2022-01-04 17:10:05,248 epoch 14 - iter 30/100 - loss 0.02028036 - samples/sec: 39.03 - lr: 0.050000\n",
      "2022-01-04 17:10:13,950 epoch 14 - iter 40/100 - loss 0.01961071 - samples/sec: 36.79 - lr: 0.050000\n",
      "2022-01-04 17:10:20,773 epoch 14 - iter 50/100 - loss 0.01965687 - samples/sec: 46.92 - lr: 0.050000\n",
      "2022-01-04 17:10:28,343 epoch 14 - iter 60/100 - loss 0.01980050 - samples/sec: 42.29 - lr: 0.050000\n",
      "2022-01-04 17:10:35,248 epoch 14 - iter 70/100 - loss 0.01939973 - samples/sec: 46.35 - lr: 0.050000\n",
      "2022-01-04 17:10:43,451 epoch 14 - iter 80/100 - loss 0.01980040 - samples/sec: 39.03 - lr: 0.050000\n",
      "2022-01-04 17:10:51,129 epoch 14 - iter 90/100 - loss 0.01976105 - samples/sec: 41.69 - lr: 0.050000\n",
      "2022-01-04 17:10:57,629 epoch 14 - iter 100/100 - loss 0.01959888 - samples/sec: 49.26 - lr: 0.050000\n",
      "2022-01-04 17:10:57,631 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:10:57,632 EPOCH 14 done: loss 0.0196 - lr 0.0500000\n",
      "2022-01-04 17:11:00,715 DEV : loss 0.008580852299928665 - f1-score (micro avg)  0.9298\n",
      "2022-01-04 17:11:00,753 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:11:00,755 saving best model\n",
      "2022-01-04 17:11:02,437 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:11:11,021 epoch 15 - iter 10/100 - loss 0.01421142 - samples/sec: 37.30 - lr: 0.050000\n",
      "2022-01-04 17:11:18,938 epoch 15 - iter 20/100 - loss 0.01688239 - samples/sec: 40.43 - lr: 0.050000\n",
      "2022-01-04 17:11:25,241 epoch 15 - iter 30/100 - loss 0.01838234 - samples/sec: 50.78 - lr: 0.050000\n",
      "2022-01-04 17:11:32,235 epoch 15 - iter 40/100 - loss 0.01902921 - samples/sec: 45.77 - lr: 0.050000\n",
      "2022-01-04 17:11:39,757 epoch 15 - iter 50/100 - loss 0.02065905 - samples/sec: 42.56 - lr: 0.050000\n",
      "2022-01-04 17:11:46,842 epoch 15 - iter 60/100 - loss 0.02103150 - samples/sec: 45.17 - lr: 0.050000\n",
      "2022-01-04 17:11:55,027 epoch 15 - iter 70/100 - loss 0.02014884 - samples/sec: 39.11 - lr: 0.050000\n",
      "2022-01-04 17:12:02,393 epoch 15 - iter 80/100 - loss 0.01971550 - samples/sec: 43.46 - lr: 0.050000\n",
      "2022-01-04 17:12:08,857 epoch 15 - iter 90/100 - loss 0.01959103 - samples/sec: 49.53 - lr: 0.050000\n",
      "2022-01-04 17:12:16,930 epoch 15 - iter 100/100 - loss 0.01960022 - samples/sec: 39.66 - lr: 0.050000\n",
      "2022-01-04 17:12:16,932 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:12:16,933 EPOCH 15 done: loss 0.0196 - lr 0.0500000\n",
      "2022-01-04 17:12:19,556 DEV : loss 0.008896318264305592 - f1-score (micro avg)  0.9144\n",
      "2022-01-04 17:12:19,595 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:12:19,597 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:12:28,065 epoch 16 - iter 10/100 - loss 0.01905228 - samples/sec: 37.81 - lr: 0.050000\n",
      "2022-01-04 17:12:35,489 epoch 16 - iter 20/100 - loss 0.01852603 - samples/sec: 43.12 - lr: 0.050000\n",
      "2022-01-04 17:12:43,036 epoch 16 - iter 30/100 - loss 0.02051193 - samples/sec: 42.42 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:12:50,332 epoch 16 - iter 40/100 - loss 0.01958036 - samples/sec: 43.87 - lr: 0.050000\n",
      "2022-01-04 17:12:56,576 epoch 16 - iter 50/100 - loss 0.01988763 - samples/sec: 51.25 - lr: 0.050000\n",
      "2022-01-04 17:13:02,810 epoch 16 - iter 60/100 - loss 0.01854202 - samples/sec: 51.36 - lr: 0.050000\n",
      "2022-01-04 17:13:09,802 epoch 16 - iter 70/100 - loss 0.01888305 - samples/sec: 45.79 - lr: 0.050000\n",
      "2022-01-04 17:13:17,002 epoch 16 - iter 80/100 - loss 0.01828588 - samples/sec: 44.46 - lr: 0.050000\n",
      "2022-01-04 17:13:22,598 epoch 16 - iter 90/100 - loss 0.01793670 - samples/sec: 57.20 - lr: 0.050000\n",
      "2022-01-04 17:13:29,800 epoch 16 - iter 100/100 - loss 0.01771855 - samples/sec: 44.46 - lr: 0.050000\n",
      "2022-01-04 17:13:29,802 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:13:29,802 EPOCH 16 done: loss 0.0177 - lr 0.0500000\n",
      "2022-01-04 17:13:31,942 DEV : loss 0.009220510721206665 - f1-score (micro avg)  0.9118\n",
      "2022-01-04 17:13:31,973 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:13:31,974 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:13:38,411 epoch 17 - iter 10/100 - loss 0.01204686 - samples/sec: 49.73 - lr: 0.050000\n",
      "2022-01-04 17:13:44,939 epoch 17 - iter 20/100 - loss 0.01680365 - samples/sec: 49.03 - lr: 0.050000\n",
      "2022-01-04 17:13:52,788 epoch 17 - iter 30/100 - loss 0.01797648 - samples/sec: 40.77 - lr: 0.050000\n",
      "2022-01-04 17:13:59,982 epoch 17 - iter 40/100 - loss 0.01809689 - samples/sec: 44.50 - lr: 0.050000\n",
      "2022-01-04 17:14:06,745 epoch 17 - iter 50/100 - loss 0.01741928 - samples/sec: 47.33 - lr: 0.050000\n",
      "2022-01-04 17:14:12,926 epoch 17 - iter 60/100 - loss 0.01755857 - samples/sec: 51.79 - lr: 0.050000\n",
      "2022-01-04 17:14:19,607 epoch 17 - iter 70/100 - loss 0.01707383 - samples/sec: 47.92 - lr: 0.050000\n",
      "2022-01-04 17:14:27,124 epoch 17 - iter 80/100 - loss 0.01732921 - samples/sec: 42.58 - lr: 0.050000\n",
      "2022-01-04 17:14:34,509 epoch 17 - iter 90/100 - loss 0.01826692 - samples/sec: 43.36 - lr: 0.050000\n",
      "2022-01-04 17:14:41,330 epoch 17 - iter 100/100 - loss 0.01799929 - samples/sec: 46.94 - lr: 0.050000\n",
      "2022-01-04 17:14:41,332 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:14:41,333 EPOCH 17 done: loss 0.0180 - lr 0.0500000\n",
      "2022-01-04 17:14:43,451 DEV : loss 0.008395090699195862 - f1-score (micro avg)  0.9171\n",
      "2022-01-04 17:14:43,486 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:14:43,488 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:14:50,276 epoch 18 - iter 10/100 - loss 0.02518428 - samples/sec: 47.16 - lr: 0.050000\n",
      "2022-01-04 17:14:57,796 epoch 18 - iter 20/100 - loss 0.02310583 - samples/sec: 42.57 - lr: 0.050000\n",
      "2022-01-04 17:15:05,373 epoch 18 - iter 30/100 - loss 0.02267619 - samples/sec: 42.24 - lr: 0.050000\n",
      "2022-01-04 17:15:13,028 epoch 18 - iter 40/100 - loss 0.02107166 - samples/sec: 41.81 - lr: 0.050000\n",
      "2022-01-04 17:15:20,384 epoch 18 - iter 50/100 - loss 0.01882888 - samples/sec: 43.51 - lr: 0.050000\n",
      "2022-01-04 17:15:27,204 epoch 18 - iter 60/100 - loss 0.01818621 - samples/sec: 46.93 - lr: 0.050000\n",
      "2022-01-04 17:15:33,718 epoch 18 - iter 70/100 - loss 0.01808462 - samples/sec: 49.13 - lr: 0.050000\n",
      "2022-01-04 17:15:40,377 epoch 18 - iter 80/100 - loss 0.01780680 - samples/sec: 48.07 - lr: 0.050000\n",
      "2022-01-04 17:15:47,067 epoch 18 - iter 90/100 - loss 0.01829012 - samples/sec: 47.86 - lr: 0.050000\n",
      "2022-01-04 17:15:52,857 epoch 18 - iter 100/100 - loss 0.01803926 - samples/sec: 55.28 - lr: 0.050000\n",
      "2022-01-04 17:15:52,859 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:15:52,860 EPOCH 18 done: loss 0.0180 - lr 0.0500000\n",
      "2022-01-04 17:15:55,078 DEV : loss 0.009172126650810242 - f1-score (micro avg)  0.9284\n",
      "Epoch    18: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2022-01-04 17:15:55,124 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:15:55,126 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:16:01,776 epoch 19 - iter 10/100 - loss 0.02198153 - samples/sec: 48.14 - lr: 0.025000\n",
      "2022-01-04 17:16:08,624 epoch 19 - iter 20/100 - loss 0.01662069 - samples/sec: 46.74 - lr: 0.025000\n",
      "2022-01-04 17:16:16,075 epoch 19 - iter 30/100 - loss 0.01672056 - samples/sec: 42.97 - lr: 0.025000\n",
      "2022-01-04 17:16:22,974 epoch 19 - iter 40/100 - loss 0.01674430 - samples/sec: 46.40 - lr: 0.025000\n",
      "2022-01-04 17:16:29,225 epoch 19 - iter 50/100 - loss 0.01505569 - samples/sec: 51.20 - lr: 0.025000\n",
      "2022-01-04 17:16:36,964 epoch 19 - iter 60/100 - loss 0.01526795 - samples/sec: 41.36 - lr: 0.025000\n",
      "2022-01-04 17:16:43,531 epoch 19 - iter 70/100 - loss 0.01579598 - samples/sec: 48.74 - lr: 0.025000\n",
      "2022-01-04 17:16:50,503 epoch 19 - iter 80/100 - loss 0.01557483 - samples/sec: 45.93 - lr: 0.025000\n",
      "2022-01-04 17:16:57,174 epoch 19 - iter 90/100 - loss 0.01647611 - samples/sec: 48.00 - lr: 0.025000\n",
      "2022-01-04 17:17:03,326 epoch 19 - iter 100/100 - loss 0.01642969 - samples/sec: 52.05 - lr: 0.025000\n",
      "2022-01-04 17:17:03,328 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:17:03,329 EPOCH 19 done: loss 0.0164 - lr 0.0250000\n",
      "2022-01-04 17:17:05,944 DEV : loss 0.008801531977951527 - f1-score (micro avg)  0.9257\n",
      "2022-01-04 17:17:05,976 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:17:05,978 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:17:12,871 epoch 20 - iter 10/100 - loss 0.01504106 - samples/sec: 46.46 - lr: 0.025000\n",
      "2022-01-04 17:17:19,634 epoch 20 - iter 20/100 - loss 0.01852484 - samples/sec: 47.33 - lr: 0.025000\n",
      "2022-01-04 17:17:26,759 epoch 20 - iter 30/100 - loss 0.01715340 - samples/sec: 44.93 - lr: 0.025000\n",
      "2022-01-04 17:17:33,149 epoch 20 - iter 40/100 - loss 0.01677786 - samples/sec: 50.10 - lr: 0.025000\n",
      "2022-01-04 17:17:40,618 epoch 20 - iter 50/100 - loss 0.01745307 - samples/sec: 42.88 - lr: 0.025000\n",
      "2022-01-04 17:17:47,441 epoch 20 - iter 60/100 - loss 0.01715080 - samples/sec: 46.94 - lr: 0.025000\n",
      "2022-01-04 17:17:55,375 epoch 20 - iter 70/100 - loss 0.01735166 - samples/sec: 40.35 - lr: 0.025000\n",
      "2022-01-04 17:18:01,924 epoch 20 - iter 80/100 - loss 0.01658803 - samples/sec: 48.89 - lr: 0.025000\n",
      "2022-01-04 17:18:07,757 epoch 20 - iter 90/100 - loss 0.01699820 - samples/sec: 54.87 - lr: 0.025000\n",
      "2022-01-04 17:18:14,496 epoch 20 - iter 100/100 - loss 0.01707288 - samples/sec: 47.49 - lr: 0.025000\n",
      "2022-01-04 17:18:14,498 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:18:14,499 EPOCH 20 done: loss 0.0171 - lr 0.0250000\n",
      "2022-01-04 17:18:16,683 DEV : loss 0.008832688443362713 - f1-score (micro avg)  0.9204\n",
      "2022-01-04 17:18:16,715 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:18:16,717 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:18:24,566 epoch 21 - iter 10/100 - loss 0.01097915 - samples/sec: 40.80 - lr: 0.025000\n",
      "2022-01-04 17:18:31,101 epoch 21 - iter 20/100 - loss 0.01425106 - samples/sec: 48.99 - lr: 0.025000\n",
      "2022-01-04 17:18:36,558 epoch 21 - iter 30/100 - loss 0.01644840 - samples/sec: 58.68 - lr: 0.025000\n",
      "2022-01-04 17:18:43,096 epoch 21 - iter 40/100 - loss 0.01587310 - samples/sec: 48.97 - lr: 0.025000\n",
      "2022-01-04 17:18:50,573 epoch 21 - iter 50/100 - loss 0.01673234 - samples/sec: 42.81 - lr: 0.025000\n",
      "2022-01-04 17:18:58,536 epoch 21 - iter 60/100 - loss 0.01617512 - samples/sec: 40.20 - lr: 0.025000\n",
      "2022-01-04 17:19:05,012 epoch 21 - iter 70/100 - loss 0.01655910 - samples/sec: 49.45 - lr: 0.025000\n",
      "2022-01-04 17:19:11,897 epoch 21 - iter 80/100 - loss 0.01656090 - samples/sec: 46.49 - lr: 0.025000\n",
      "2022-01-04 17:19:19,177 epoch 21 - iter 90/100 - loss 0.01697116 - samples/sec: 43.98 - lr: 0.025000\n",
      "2022-01-04 17:19:26,075 epoch 21 - iter 100/100 - loss 0.01677906 - samples/sec: 46.40 - lr: 0.025000\n",
      "2022-01-04 17:19:26,076 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:19:26,078 EPOCH 21 done: loss 0.0168 - lr 0.0250000\n",
      "2022-01-04 17:19:28,266 DEV : loss 0.008226054720580578 - f1-score (micro avg)  0.9287\n",
      "2022-01-04 17:19:28,308 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:19:28,310 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:19:35,593 epoch 22 - iter 10/100 - loss 0.02480870 - samples/sec: 43.95 - lr: 0.025000\n",
      "2022-01-04 17:19:43,005 epoch 22 - iter 20/100 - loss 0.02053399 - samples/sec: 43.18 - lr: 0.025000\n",
      "2022-01-04 17:19:50,419 epoch 22 - iter 30/100 - loss 0.01961543 - samples/sec: 43.18 - lr: 0.025000\n",
      "2022-01-04 17:19:56,865 epoch 22 - iter 40/100 - loss 0.01736762 - samples/sec: 49.67 - lr: 0.025000\n",
      "2022-01-04 17:20:03,341 epoch 22 - iter 50/100 - loss 0.01646511 - samples/sec: 49.43 - lr: 0.025000\n",
      "2022-01-04 17:20:09,908 epoch 22 - iter 60/100 - loss 0.01752673 - samples/sec: 48.75 - lr: 0.025000\n",
      "2022-01-04 17:20:17,370 epoch 22 - iter 70/100 - loss 0.01801423 - samples/sec: 42.92 - lr: 0.025000\n",
      "2022-01-04 17:20:23,632 epoch 22 - iter 80/100 - loss 0.01789591 - samples/sec: 51.13 - lr: 0.025000\n",
      "2022-01-04 17:20:30,494 epoch 22 - iter 90/100 - loss 0.01704770 - samples/sec: 46.66 - lr: 0.025000\n",
      "2022-01-04 17:20:37,292 epoch 22 - iter 100/100 - loss 0.01707187 - samples/sec: 47.10 - lr: 0.025000\n",
      "2022-01-04 17:20:37,293 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:20:37,294 EPOCH 22 done: loss 0.0171 - lr 0.0250000\n",
      "2022-01-04 17:20:39,440 DEV : loss 0.00763884698972106 - f1-score (micro avg)  0.9291\n",
      "Epoch    22: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2022-01-04 17:20:39,481 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:20:39,483 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:20:45,993 epoch 23 - iter 10/100 - loss 0.01634338 - samples/sec: 49.17 - lr: 0.012500\n",
      "2022-01-04 17:20:52,123 epoch 23 - iter 20/100 - loss 0.01542216 - samples/sec: 52.21 - lr: 0.012500\n",
      "2022-01-04 17:20:59,185 epoch 23 - iter 30/100 - loss 0.01707498 - samples/sec: 45.34 - lr: 0.012500\n",
      "2022-01-04 17:21:07,114 epoch 23 - iter 40/100 - loss 0.01725011 - samples/sec: 40.37 - lr: 0.012500\n",
      "2022-01-04 17:21:13,872 epoch 23 - iter 50/100 - loss 0.01529227 - samples/sec: 47.37 - lr: 0.012500\n",
      "2022-01-04 17:21:20,855 epoch 23 - iter 60/100 - loss 0.01772013 - samples/sec: 45.86 - lr: 0.012500\n",
      "2022-01-04 17:21:27,430 epoch 23 - iter 70/100 - loss 0.01744547 - samples/sec: 48.70 - lr: 0.012500\n",
      "2022-01-04 17:21:34,589 epoch 23 - iter 80/100 - loss 0.01673400 - samples/sec: 44.71 - lr: 0.012500\n",
      "2022-01-04 17:21:41,409 epoch 23 - iter 90/100 - loss 0.01803799 - samples/sec: 46.94 - lr: 0.012500\n",
      "2022-01-04 17:21:48,264 epoch 23 - iter 100/100 - loss 0.01717189 - samples/sec: 46.70 - lr: 0.012500\n",
      "2022-01-04 17:21:48,266 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:21:48,267 EPOCH 23 done: loss 0.0172 - lr 0.0125000\n",
      "2022-01-04 17:21:50,418 DEV : loss 0.008344640024006367 - f1-score (micro avg)  0.9284\n",
      "2022-01-04 17:21:50,448 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:21:50,451 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:21:57,336 epoch 24 - iter 10/100 - loss 0.01773060 - samples/sec: 46.50 - lr: 0.012500\n",
      "2022-01-04 17:22:03,419 epoch 24 - iter 20/100 - loss 0.01855563 - samples/sec: 52.64 - lr: 0.012500\n",
      "2022-01-04 17:22:09,903 epoch 24 - iter 30/100 - loss 0.01825663 - samples/sec: 49.38 - lr: 0.012500\n",
      "2022-01-04 17:22:17,691 epoch 24 - iter 40/100 - loss 0.01763889 - samples/sec: 41.10 - lr: 0.012500\n",
      "2022-01-04 17:22:25,476 epoch 24 - iter 50/100 - loss 0.01854911 - samples/sec: 41.11 - lr: 0.012500\n",
      "2022-01-04 17:22:33,948 epoch 24 - iter 60/100 - loss 0.01767942 - samples/sec: 37.78 - lr: 0.012500\n",
      "2022-01-04 17:22:42,138 epoch 24 - iter 70/100 - loss 0.01731501 - samples/sec: 39.08 - lr: 0.012500\n",
      "2022-01-04 17:22:49,708 epoch 24 - iter 80/100 - loss 0.01784794 - samples/sec: 42.28 - lr: 0.012500\n",
      "2022-01-04 17:22:57,343 epoch 24 - iter 90/100 - loss 0.01723016 - samples/sec: 41.94 - lr: 0.012500\n",
      "2022-01-04 17:23:05,632 epoch 24 - iter 100/100 - loss 0.01627656 - samples/sec: 38.63 - lr: 0.012500\n",
      "2022-01-04 17:23:05,634 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:23:05,635 EPOCH 24 done: loss 0.0163 - lr 0.0125000\n",
      "2022-01-04 17:23:08,447 DEV : loss 0.008445382118225098 - f1-score (micro avg)  0.931\n",
      "2022-01-04 17:23:08,483 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:23:08,484 saving best model\n",
      "2022-01-04 17:23:10,561 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:23:18,690 epoch 25 - iter 10/100 - loss 0.01224042 - samples/sec: 39.38 - lr: 0.012500\n",
      "2022-01-04 17:23:26,269 epoch 25 - iter 20/100 - loss 0.01489540 - samples/sec: 42.25 - lr: 0.012500\n",
      "2022-01-04 17:23:32,743 epoch 25 - iter 30/100 - loss 0.01578902 - samples/sec: 49.46 - lr: 0.012500\n",
      "2022-01-04 17:23:40,354 epoch 25 - iter 40/100 - loss 0.01567297 - samples/sec: 42.05 - lr: 0.012500\n",
      "2022-01-04 17:23:47,472 epoch 25 - iter 50/100 - loss 0.01504091 - samples/sec: 44.97 - lr: 0.012500\n",
      "2022-01-04 17:23:54,301 epoch 25 - iter 60/100 - loss 0.01591821 - samples/sec: 46.87 - lr: 0.012500\n",
      "2022-01-04 17:24:01,756 epoch 25 - iter 70/100 - loss 0.01560499 - samples/sec: 42.94 - lr: 0.012500\n",
      "2022-01-04 17:24:09,155 epoch 25 - iter 80/100 - loss 0.01621513 - samples/sec: 43.26 - lr: 0.012500\n",
      "2022-01-04 17:24:15,948 epoch 25 - iter 90/100 - loss 0.01585728 - samples/sec: 47.11 - lr: 0.012500\n",
      "2022-01-04 17:24:22,921 epoch 25 - iter 100/100 - loss 0.01555611 - samples/sec: 45.91 - lr: 0.012500\n",
      "2022-01-04 17:24:22,923 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:24:22,923 EPOCH 25 done: loss 0.0156 - lr 0.0125000\n",
      "2022-01-04 17:24:25,294 DEV : loss 0.007561758626252413 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:24:25,333 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:24:25,335 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:24:32,284 epoch 26 - iter 10/100 - loss 0.01612268 - samples/sec: 46.06 - lr: 0.012500\n",
      "2022-01-04 17:24:39,172 epoch 26 - iter 20/100 - loss 0.01227899 - samples/sec: 46.46 - lr: 0.012500\n",
      "2022-01-04 17:24:46,190 epoch 26 - iter 30/100 - loss 0.01182866 - samples/sec: 45.61 - lr: 0.012500\n",
      "2022-01-04 17:24:53,166 epoch 26 - iter 40/100 - loss 0.01387798 - samples/sec: 45.90 - lr: 0.012500\n",
      "2022-01-04 17:25:00,158 epoch 26 - iter 50/100 - loss 0.01541963 - samples/sec: 45.78 - lr: 0.012500\n",
      "2022-01-04 17:25:07,504 epoch 26 - iter 60/100 - loss 0.01610520 - samples/sec: 43.57 - lr: 0.012500\n",
      "2022-01-04 17:25:14,879 epoch 26 - iter 70/100 - loss 0.01655598 - samples/sec: 43.40 - lr: 0.012500\n",
      "2022-01-04 17:25:23,162 epoch 26 - iter 80/100 - loss 0.01586544 - samples/sec: 38.65 - lr: 0.012500\n",
      "2022-01-04 17:25:30,314 epoch 26 - iter 90/100 - loss 0.01586677 - samples/sec: 44.76 - lr: 0.012500\n",
      "2022-01-04 17:25:37,438 epoch 26 - iter 100/100 - loss 0.01562280 - samples/sec: 44.93 - lr: 0.012500\n",
      "2022-01-04 17:25:37,440 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:25:37,441 EPOCH 26 done: loss 0.0156 - lr 0.0125000\n",
      "2022-01-04 17:25:39,756 DEV : loss 0.007863948121666908 - f1-score (micro avg)  0.9265\n",
      "2022-01-04 17:25:39,790 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:25:39,793 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:25:46,971 epoch 27 - iter 10/100 - loss 0.01641604 - samples/sec: 44.61 - lr: 0.012500\n",
      "2022-01-04 17:25:54,660 epoch 27 - iter 20/100 - loss 0.01673598 - samples/sec: 41.64 - lr: 0.012500\n",
      "2022-01-04 17:26:01,718 epoch 27 - iter 30/100 - loss 0.01494254 - samples/sec: 45.35 - lr: 0.012500\n",
      "2022-01-04 17:26:09,586 epoch 27 - iter 40/100 - loss 0.01348185 - samples/sec: 40.68 - lr: 0.012500\n",
      "2022-01-04 17:26:16,563 epoch 27 - iter 50/100 - loss 0.01348622 - samples/sec: 45.89 - lr: 0.012500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:26:24,290 epoch 27 - iter 60/100 - loss 0.01484727 - samples/sec: 41.43 - lr: 0.012500\n",
      "2022-01-04 17:26:31,935 epoch 27 - iter 70/100 - loss 0.01500879 - samples/sec: 41.87 - lr: 0.012500\n",
      "2022-01-04 17:26:38,254 epoch 27 - iter 80/100 - loss 0.01550462 - samples/sec: 50.67 - lr: 0.012500\n",
      "2022-01-04 17:26:45,152 epoch 27 - iter 90/100 - loss 0.01533794 - samples/sec: 46.40 - lr: 0.012500\n",
      "2022-01-04 17:26:52,430 epoch 27 - iter 100/100 - loss 0.01525693 - samples/sec: 44.00 - lr: 0.012500\n",
      "2022-01-04 17:26:52,431 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:26:52,432 EPOCH 27 done: loss 0.0153 - lr 0.0125000\n",
      "2022-01-04 17:26:54,865 DEV : loss 0.007790029514580965 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:26:54,899 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:26:54,901 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:27:01,402 epoch 28 - iter 10/100 - loss 0.01794384 - samples/sec: 49.23 - lr: 0.012500\n",
      "2022-01-04 17:27:08,083 epoch 28 - iter 20/100 - loss 0.01686717 - samples/sec: 47.92 - lr: 0.012500\n",
      "2022-01-04 17:27:16,914 epoch 28 - iter 30/100 - loss 0.01525858 - samples/sec: 36.25 - lr: 0.012500\n",
      "2022-01-04 17:27:24,979 epoch 28 - iter 40/100 - loss 0.01525492 - samples/sec: 39.70 - lr: 0.012500\n",
      "2022-01-04 17:27:31,964 epoch 28 - iter 50/100 - loss 0.01534798 - samples/sec: 45.83 - lr: 0.012500\n",
      "2022-01-04 17:27:39,186 epoch 28 - iter 60/100 - loss 0.01452958 - samples/sec: 44.31 - lr: 0.012500\n",
      "2022-01-04 17:27:46,527 epoch 28 - iter 70/100 - loss 0.01517091 - samples/sec: 43.61 - lr: 0.012500\n",
      "2022-01-04 17:27:54,086 epoch 28 - iter 80/100 - loss 0.01542570 - samples/sec: 42.35 - lr: 0.012500\n",
      "2022-01-04 17:28:01,873 epoch 28 - iter 90/100 - loss 0.01565791 - samples/sec: 41.11 - lr: 0.012500\n",
      "2022-01-04 17:28:08,243 epoch 28 - iter 100/100 - loss 0.01622946 - samples/sec: 50.25 - lr: 0.012500\n",
      "2022-01-04 17:28:08,244 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:28:08,245 EPOCH 28 done: loss 0.0162 - lr 0.0125000\n",
      "2022-01-04 17:28:10,647 DEV : loss 0.007349416147917509 - f1-score (micro avg)  0.9291\n",
      "Epoch    28: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2022-01-04 17:28:10,688 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:28:10,690 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:28:17,502 epoch 29 - iter 10/100 - loss 0.02248604 - samples/sec: 47.00 - lr: 0.006250\n",
      "2022-01-04 17:28:25,274 epoch 29 - iter 20/100 - loss 0.02038725 - samples/sec: 41.19 - lr: 0.006250\n",
      "2022-01-04 17:28:32,634 epoch 29 - iter 30/100 - loss 0.01999731 - samples/sec: 43.49 - lr: 0.006250\n",
      "2022-01-04 17:28:40,824 epoch 29 - iter 40/100 - loss 0.01770237 - samples/sec: 39.08 - lr: 0.006250\n",
      "2022-01-04 17:28:47,581 epoch 29 - iter 50/100 - loss 0.01632768 - samples/sec: 47.41 - lr: 0.006250\n",
      "2022-01-04 17:28:55,396 epoch 29 - iter 60/100 - loss 0.01633250 - samples/sec: 40.97 - lr: 0.006250\n",
      "2022-01-04 17:29:02,994 epoch 29 - iter 70/100 - loss 0.01630968 - samples/sec: 42.14 - lr: 0.006250\n",
      "2022-01-04 17:29:09,392 epoch 29 - iter 80/100 - loss 0.01608488 - samples/sec: 50.04 - lr: 0.006250\n",
      "2022-01-04 17:29:16,939 epoch 29 - iter 90/100 - loss 0.01614799 - samples/sec: 42.43 - lr: 0.006250\n",
      "2022-01-04 17:29:23,237 epoch 29 - iter 100/100 - loss 0.01552031 - samples/sec: 50.82 - lr: 0.006250\n",
      "2022-01-04 17:29:23,239 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:29:23,240 EPOCH 29 done: loss 0.0155 - lr 0.0062500\n",
      "2022-01-04 17:29:26,027 DEV : loss 0.007594699505716562 - f1-score (micro avg)  0.9291\n",
      "2022-01-04 17:29:26,056 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:29:26,058 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:29:33,387 epoch 30 - iter 10/100 - loss 0.01466176 - samples/sec: 43.69 - lr: 0.006250\n",
      "2022-01-04 17:29:40,086 epoch 30 - iter 20/100 - loss 0.01369984 - samples/sec: 47.79 - lr: 0.006250\n",
      "2022-01-04 17:29:47,659 epoch 30 - iter 30/100 - loss 0.01432914 - samples/sec: 42.28 - lr: 0.006250\n",
      "2022-01-04 17:29:55,338 epoch 30 - iter 40/100 - loss 0.01401193 - samples/sec: 41.69 - lr: 0.006250\n",
      "2022-01-04 17:30:03,641 epoch 30 - iter 50/100 - loss 0.01269707 - samples/sec: 38.55 - lr: 0.006250\n",
      "2022-01-04 17:30:11,634 epoch 30 - iter 60/100 - loss 0.01424098 - samples/sec: 40.04 - lr: 0.006250\n",
      "2022-01-04 17:30:19,035 epoch 30 - iter 70/100 - loss 0.01477975 - samples/sec: 43.26 - lr: 0.006250\n",
      "2022-01-04 17:30:26,575 epoch 30 - iter 80/100 - loss 0.01459687 - samples/sec: 42.45 - lr: 0.006250\n",
      "2022-01-04 17:30:33,150 epoch 30 - iter 90/100 - loss 0.01493781 - samples/sec: 48.68 - lr: 0.006250\n",
      "2022-01-04 17:30:39,574 epoch 30 - iter 100/100 - loss 0.01556983 - samples/sec: 49.85 - lr: 0.006250\n",
      "2022-01-04 17:30:39,576 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:30:39,577 EPOCH 30 done: loss 0.0156 - lr 0.0062500\n",
      "2022-01-04 17:30:41,960 DEV : loss 0.007430193945765495 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:30:41,991 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:30:41,994 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:30:49,018 epoch 31 - iter 10/100 - loss 0.01423372 - samples/sec: 45.58 - lr: 0.006250\n",
      "2022-01-04 17:30:55,980 epoch 31 - iter 20/100 - loss 0.01573845 - samples/sec: 45.99 - lr: 0.006250\n",
      "2022-01-04 17:31:04,130 epoch 31 - iter 30/100 - loss 0.01860661 - samples/sec: 39.28 - lr: 0.006250\n",
      "2022-01-04 17:31:11,819 epoch 31 - iter 40/100 - loss 0.01776091 - samples/sec: 41.63 - lr: 0.006250\n",
      "2022-01-04 17:31:19,868 epoch 31 - iter 50/100 - loss 0.01686790 - samples/sec: 39.77 - lr: 0.006250\n",
      "2022-01-04 17:31:27,132 epoch 31 - iter 60/100 - loss 0.01606047 - samples/sec: 44.06 - lr: 0.006250\n",
      "2022-01-04 17:31:34,094 epoch 31 - iter 70/100 - loss 0.01586725 - samples/sec: 45.99 - lr: 0.006250\n",
      "2022-01-04 17:31:41,211 epoch 31 - iter 80/100 - loss 0.01724052 - samples/sec: 44.99 - lr: 0.006250\n",
      "2022-01-04 17:31:47,468 epoch 31 - iter 90/100 - loss 0.01722462 - samples/sec: 51.15 - lr: 0.006250\n",
      "2022-01-04 17:31:54,213 epoch 31 - iter 100/100 - loss 0.01704150 - samples/sec: 47.47 - lr: 0.006250\n",
      "2022-01-04 17:31:54,215 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:31:54,216 EPOCH 31 done: loss 0.0170 - lr 0.0062500\n",
      "2022-01-04 17:31:56,503 DEV : loss 0.0073374914936721325 - f1-score (micro avg)  0.9291\n",
      "2022-01-04 17:31:56,538 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:31:56,540 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:32:03,257 epoch 32 - iter 10/100 - loss 0.01365829 - samples/sec: 47.65 - lr: 0.006250\n",
      "2022-01-04 17:32:11,987 epoch 32 - iter 20/100 - loss 0.01287958 - samples/sec: 36.66 - lr: 0.006250\n",
      "2022-01-04 17:32:19,544 epoch 32 - iter 30/100 - loss 0.01631991 - samples/sec: 42.35 - lr: 0.006250\n",
      "2022-01-04 17:32:27,095 epoch 32 - iter 40/100 - loss 0.01479568 - samples/sec: 42.42 - lr: 0.006250\n",
      "2022-01-04 17:32:33,770 epoch 32 - iter 50/100 - loss 0.01669419 - samples/sec: 47.95 - lr: 0.006250\n",
      "2022-01-04 17:32:41,114 epoch 32 - iter 60/100 - loss 0.01663061 - samples/sec: 43.60 - lr: 0.006250\n",
      "2022-01-04 17:32:47,951 epoch 32 - iter 70/100 - loss 0.01585692 - samples/sec: 46.82 - lr: 0.006250\n",
      "2022-01-04 17:32:55,133 epoch 32 - iter 80/100 - loss 0.01530430 - samples/sec: 44.56 - lr: 0.006250\n",
      "2022-01-04 17:33:02,976 epoch 32 - iter 90/100 - loss 0.01562704 - samples/sec: 40.82 - lr: 0.006250\n",
      "2022-01-04 17:33:10,172 epoch 32 - iter 100/100 - loss 0.01530833 - samples/sec: 44.50 - lr: 0.006250\n",
      "2022-01-04 17:33:10,173 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:33:10,175 EPOCH 32 done: loss 0.0153 - lr 0.0062500\n",
      "2022-01-04 17:33:12,554 DEV : loss 0.007577013690024614 - f1-score (micro avg)  0.9314\n",
      "2022-01-04 17:33:12,595 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:33:12,597 saving best model\n",
      "2022-01-04 17:33:14,365 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:33:21,965 epoch 33 - iter 10/100 - loss 0.01550735 - samples/sec: 42.12 - lr: 0.006250\n",
      "2022-01-04 17:33:29,425 epoch 33 - iter 20/100 - loss 0.01427847 - samples/sec: 42.91 - lr: 0.006250\n",
      "2022-01-04 17:33:36,670 epoch 33 - iter 30/100 - loss 0.01580956 - samples/sec: 44.18 - lr: 0.006250\n",
      "2022-01-04 17:33:44,442 epoch 33 - iter 40/100 - loss 0.01642879 - samples/sec: 41.19 - lr: 0.006250\n",
      "2022-01-04 17:33:51,439 epoch 33 - iter 50/100 - loss 0.01575623 - samples/sec: 45.74 - lr: 0.006250\n",
      "2022-01-04 17:33:58,943 epoch 33 - iter 60/100 - loss 0.01491652 - samples/sec: 42.67 - lr: 0.006250\n",
      "2022-01-04 17:34:06,341 epoch 33 - iter 70/100 - loss 0.01557764 - samples/sec: 43.27 - lr: 0.006250\n",
      "2022-01-04 17:34:13,399 epoch 33 - iter 80/100 - loss 0.01565205 - samples/sec: 45.35 - lr: 0.006250\n",
      "2022-01-04 17:34:20,552 epoch 33 - iter 90/100 - loss 0.01547650 - samples/sec: 44.76 - lr: 0.006250\n",
      "2022-01-04 17:34:26,916 epoch 33 - iter 100/100 - loss 0.01533415 - samples/sec: 50.32 - lr: 0.006250\n",
      "2022-01-04 17:34:26,917 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:34:26,918 EPOCH 33 done: loss 0.0153 - lr 0.0062500\n",
      "2022-01-04 17:34:29,600 DEV : loss 0.007726284209638834 - f1-score (micro avg)  0.9314\n",
      "2022-01-04 17:34:29,633 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:34:29,636 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:34:36,731 epoch 34 - iter 10/100 - loss 0.01868488 - samples/sec: 45.12 - lr: 0.006250\n",
      "2022-01-04 17:34:45,032 epoch 34 - iter 20/100 - loss 0.01684239 - samples/sec: 38.56 - lr: 0.006250\n",
      "2022-01-04 17:34:52,077 epoch 34 - iter 30/100 - loss 0.01729798 - samples/sec: 45.46 - lr: 0.006250\n",
      "2022-01-04 17:34:59,300 epoch 34 - iter 40/100 - loss 0.01596237 - samples/sec: 44.32 - lr: 0.006250\n",
      "2022-01-04 17:35:07,068 epoch 34 - iter 50/100 - loss 0.01497552 - samples/sec: 41.21 - lr: 0.006250\n",
      "2022-01-04 17:35:15,134 epoch 34 - iter 60/100 - loss 0.01409792 - samples/sec: 39.69 - lr: 0.006250\n",
      "2022-01-04 17:35:22,728 epoch 34 - iter 70/100 - loss 0.01401152 - samples/sec: 42.16 - lr: 0.006250\n",
      "2022-01-04 17:35:29,254 epoch 34 - iter 80/100 - loss 0.01448100 - samples/sec: 49.06 - lr: 0.006250\n",
      "2022-01-04 17:35:36,892 epoch 34 - iter 90/100 - loss 0.01489835 - samples/sec: 41.92 - lr: 0.006250\n",
      "2022-01-04 17:35:43,117 epoch 34 - iter 100/100 - loss 0.01530373 - samples/sec: 51.42 - lr: 0.006250\n",
      "2022-01-04 17:35:43,119 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:35:43,120 EPOCH 34 done: loss 0.0153 - lr 0.0062500\n",
      "2022-01-04 17:35:45,400 DEV : loss 0.007559220306575298 - f1-score (micro avg)  0.9314\n",
      "2022-01-04 17:35:45,438 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:35:45,440 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:35:52,283 epoch 35 - iter 10/100 - loss 0.00998918 - samples/sec: 46.77 - lr: 0.006250\n",
      "2022-01-04 17:35:59,952 epoch 35 - iter 20/100 - loss 0.01416475 - samples/sec: 41.76 - lr: 0.006250\n",
      "2022-01-04 17:36:06,871 epoch 35 - iter 30/100 - loss 0.01537798 - samples/sec: 46.26 - lr: 0.006250\n",
      "2022-01-04 17:36:12,975 epoch 35 - iter 40/100 - loss 0.01550750 - samples/sec: 52.47 - lr: 0.006250\n",
      "2022-01-04 17:36:21,885 epoch 35 - iter 50/100 - loss 0.01522176 - samples/sec: 35.92 - lr: 0.006250\n",
      "2022-01-04 17:36:28,858 epoch 35 - iter 60/100 - loss 0.01644802 - samples/sec: 45.90 - lr: 0.006250\n",
      "2022-01-04 17:36:36,729 epoch 35 - iter 70/100 - loss 0.01621797 - samples/sec: 40.68 - lr: 0.006250\n",
      "2022-01-04 17:36:43,747 epoch 35 - iter 80/100 - loss 0.01637588 - samples/sec: 45.62 - lr: 0.006250\n",
      "2022-01-04 17:36:51,306 epoch 35 - iter 90/100 - loss 0.01568645 - samples/sec: 42.34 - lr: 0.006250\n",
      "2022-01-04 17:36:57,952 epoch 35 - iter 100/100 - loss 0.01527303 - samples/sec: 48.17 - lr: 0.006250\n",
      "2022-01-04 17:36:57,953 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:36:57,954 EPOCH 35 done: loss 0.0153 - lr 0.0062500\n",
      "2022-01-04 17:37:00,313 DEV : loss 0.007494282443076372 - f1-score (micro avg)  0.9314\n",
      "2022-01-04 17:37:00,356 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:37:00,358 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:37:06,901 epoch 36 - iter 10/100 - loss 0.02139306 - samples/sec: 48.93 - lr: 0.006250\n",
      "2022-01-04 17:37:15,006 epoch 36 - iter 20/100 - loss 0.01451505 - samples/sec: 39.50 - lr: 0.006250\n",
      "2022-01-04 17:37:22,038 epoch 36 - iter 30/100 - loss 0.01646178 - samples/sec: 45.52 - lr: 0.006250\n",
      "2022-01-04 17:37:29,572 epoch 36 - iter 40/100 - loss 0.01605240 - samples/sec: 42.48 - lr: 0.006250\n",
      "2022-01-04 17:37:36,174 epoch 36 - iter 50/100 - loss 0.01502737 - samples/sec: 48.49 - lr: 0.006250\n",
      "2022-01-04 17:37:44,401 epoch 36 - iter 60/100 - loss 0.01417202 - samples/sec: 38.92 - lr: 0.006250\n",
      "2022-01-04 17:37:51,188 epoch 36 - iter 70/100 - loss 0.01437468 - samples/sec: 47.15 - lr: 0.006250\n",
      "2022-01-04 17:37:59,290 epoch 36 - iter 80/100 - loss 0.01465307 - samples/sec: 39.50 - lr: 0.006250\n",
      "2022-01-04 17:38:05,552 epoch 36 - iter 90/100 - loss 0.01462483 - samples/sec: 51.13 - lr: 0.006250\n",
      "2022-01-04 17:38:12,173 epoch 36 - iter 100/100 - loss 0.01498262 - samples/sec: 48.36 - lr: 0.006250\n",
      "2022-01-04 17:38:12,174 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:38:12,175 EPOCH 36 done: loss 0.0150 - lr 0.0062500\n",
      "2022-01-04 17:38:14,490 DEV : loss 0.00748034892603755 - f1-score (micro avg)  0.9314\n",
      "2022-01-04 17:38:14,526 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:38:14,528 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:38:22,287 epoch 37 - iter 10/100 - loss 0.01529468 - samples/sec: 41.25 - lr: 0.006250\n",
      "2022-01-04 17:38:29,184 epoch 37 - iter 20/100 - loss 0.01391308 - samples/sec: 46.42 - lr: 0.006250\n",
      "2022-01-04 17:38:36,130 epoch 37 - iter 30/100 - loss 0.01412748 - samples/sec: 46.08 - lr: 0.006250\n",
      "2022-01-04 17:38:43,596 epoch 37 - iter 40/100 - loss 0.01297210 - samples/sec: 42.88 - lr: 0.006250\n",
      "2022-01-04 17:38:50,462 epoch 37 - iter 50/100 - loss 0.01270764 - samples/sec: 46.63 - lr: 0.006250\n",
      "2022-01-04 17:38:57,946 epoch 37 - iter 60/100 - loss 0.01340380 - samples/sec: 42.77 - lr: 0.006250\n",
      "2022-01-04 17:39:06,125 epoch 37 - iter 70/100 - loss 0.01497323 - samples/sec: 39.13 - lr: 0.006250\n",
      "2022-01-04 17:39:13,135 epoch 37 - iter 80/100 - loss 0.01439667 - samples/sec: 45.65 - lr: 0.006250\n",
      "2022-01-04 17:39:20,142 epoch 37 - iter 90/100 - loss 0.01418220 - samples/sec: 45.69 - lr: 0.006250\n",
      "2022-01-04 17:39:27,115 epoch 37 - iter 100/100 - loss 0.01450929 - samples/sec: 45.91 - lr: 0.006250\n",
      "2022-01-04 17:39:27,116 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:39:27,118 EPOCH 37 done: loss 0.0145 - lr 0.0062500\n",
      "2022-01-04 17:39:29,425 DEV : loss 0.00743261119350791 - f1-score (micro avg)  0.9314\n",
      "2022-01-04 17:39:29,469 BAD EPOCHS (no improvement): 0\n",
      "2022-01-04 17:39:29,471 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:39:36,354 epoch 38 - iter 10/100 - loss 0.01649811 - samples/sec: 46.52 - lr: 0.006250\n",
      "2022-01-04 17:39:43,309 epoch 38 - iter 20/100 - loss 0.01629742 - samples/sec: 46.02 - lr: 0.006250\n",
      "2022-01-04 17:39:49,974 epoch 38 - iter 30/100 - loss 0.01569888 - samples/sec: 48.04 - lr: 0.006250\n",
      "2022-01-04 17:39:57,281 epoch 38 - iter 40/100 - loss 0.01520258 - samples/sec: 43.82 - lr: 0.006250\n",
      "2022-01-04 17:40:03,415 epoch 38 - iter 50/100 - loss 0.01556876 - samples/sec: 52.20 - lr: 0.006250\n",
      "2022-01-04 17:40:11,875 epoch 38 - iter 60/100 - loss 0.01521002 - samples/sec: 37.84 - lr: 0.006250\n",
      "2022-01-04 17:40:19,293 epoch 38 - iter 70/100 - loss 0.01453697 - samples/sec: 43.16 - lr: 0.006250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:40:26,987 epoch 38 - iter 80/100 - loss 0.01417097 - samples/sec: 41.62 - lr: 0.006250\n",
      "2022-01-04 17:40:34,550 epoch 38 - iter 90/100 - loss 0.01470666 - samples/sec: 42.33 - lr: 0.006250\n",
      "2022-01-04 17:40:41,543 epoch 38 - iter 100/100 - loss 0.01494981 - samples/sec: 45.77 - lr: 0.006250\n",
      "2022-01-04 17:40:41,545 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:40:41,546 EPOCH 38 done: loss 0.0149 - lr 0.0062500\n",
      "2022-01-04 17:40:44,285 DEV : loss 0.007157016545534134 - f1-score (micro avg)  0.9246\n",
      "2022-01-04 17:40:44,316 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:40:44,318 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:40:51,637 epoch 39 - iter 10/100 - loss 0.01850129 - samples/sec: 43.74 - lr: 0.006250\n",
      "2022-01-04 17:40:59,087 epoch 39 - iter 20/100 - loss 0.01488481 - samples/sec: 42.96 - lr: 0.006250\n",
      "2022-01-04 17:41:08,477 epoch 39 - iter 30/100 - loss 0.01667790 - samples/sec: 34.09 - lr: 0.006250\n",
      "2022-01-04 17:41:15,286 epoch 39 - iter 40/100 - loss 0.01664252 - samples/sec: 47.01 - lr: 0.006250\n",
      "2022-01-04 17:41:22,389 epoch 39 - iter 50/100 - loss 0.01473628 - samples/sec: 45.08 - lr: 0.006250\n",
      "2022-01-04 17:41:29,678 epoch 39 - iter 60/100 - loss 0.01430534 - samples/sec: 43.92 - lr: 0.006250\n",
      "2022-01-04 17:41:37,432 epoch 39 - iter 70/100 - loss 0.01435146 - samples/sec: 41.28 - lr: 0.006250\n",
      "2022-01-04 17:41:44,929 epoch 39 - iter 80/100 - loss 0.01525001 - samples/sec: 42.70 - lr: 0.006250\n",
      "2022-01-04 17:41:51,635 epoch 39 - iter 90/100 - loss 0.01491005 - samples/sec: 47.74 - lr: 0.006250\n",
      "2022-01-04 17:41:57,737 epoch 39 - iter 100/100 - loss 0.01471603 - samples/sec: 52.45 - lr: 0.006250\n",
      "2022-01-04 17:41:57,738 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:41:57,739 EPOCH 39 done: loss 0.0147 - lr 0.0062500\n",
      "2022-01-04 17:41:59,973 DEV : loss 0.007437929976731539 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:42:00,012 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:42:00,014 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:42:07,885 epoch 40 - iter 10/100 - loss 0.01457163 - samples/sec: 40.68 - lr: 0.006250\n",
      "2022-01-04 17:42:15,253 epoch 40 - iter 20/100 - loss 0.01254129 - samples/sec: 43.46 - lr: 0.006250\n",
      "2022-01-04 17:42:23,346 epoch 40 - iter 30/100 - loss 0.01681576 - samples/sec: 39.55 - lr: 0.006250\n",
      "2022-01-04 17:42:30,457 epoch 40 - iter 40/100 - loss 0.01676598 - samples/sec: 45.01 - lr: 0.006250\n",
      "2022-01-04 17:42:37,246 epoch 40 - iter 50/100 - loss 0.01694161 - samples/sec: 47.16 - lr: 0.006250\n",
      "2022-01-04 17:42:43,137 epoch 40 - iter 60/100 - loss 0.01693977 - samples/sec: 54.34 - lr: 0.006250\n",
      "2022-01-04 17:42:50,216 epoch 40 - iter 70/100 - loss 0.01635925 - samples/sec: 45.22 - lr: 0.006250\n",
      "2022-01-04 17:42:57,358 epoch 40 - iter 80/100 - loss 0.01639323 - samples/sec: 44.82 - lr: 0.006250\n",
      "2022-01-04 17:43:04,637 epoch 40 - iter 90/100 - loss 0.01569070 - samples/sec: 43.98 - lr: 0.006250\n",
      "2022-01-04 17:43:10,784 epoch 40 - iter 100/100 - loss 0.01529770 - samples/sec: 52.07 - lr: 0.006250\n",
      "2022-01-04 17:43:10,785 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:43:10,786 EPOCH 40 done: loss 0.0153 - lr 0.0062500\n",
      "2022-01-04 17:43:13,092 DEV : loss 0.007203093264251947 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:43:13,123 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:43:13,125 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:43:19,846 epoch 41 - iter 10/100 - loss 0.01234972 - samples/sec: 47.65 - lr: 0.006250\n",
      "2022-01-04 17:43:26,777 epoch 41 - iter 20/100 - loss 0.01629853 - samples/sec: 46.18 - lr: 0.006250\n",
      "2022-01-04 17:43:34,390 epoch 41 - iter 30/100 - loss 0.01436692 - samples/sec: 42.04 - lr: 0.006250\n",
      "2022-01-04 17:43:42,210 epoch 41 - iter 40/100 - loss 0.01552395 - samples/sec: 40.93 - lr: 0.006250\n",
      "2022-01-04 17:43:48,778 epoch 41 - iter 50/100 - loss 0.01596698 - samples/sec: 48.75 - lr: 0.006250\n",
      "2022-01-04 17:43:57,317 epoch 41 - iter 60/100 - loss 0.01566740 - samples/sec: 37.49 - lr: 0.006250\n",
      "2022-01-04 17:44:04,117 epoch 41 - iter 70/100 - loss 0.01609144 - samples/sec: 47.08 - lr: 0.006250\n",
      "2022-01-04 17:44:10,748 epoch 41 - iter 80/100 - loss 0.01647422 - samples/sec: 48.27 - lr: 0.006250\n",
      "2022-01-04 17:44:18,579 epoch 41 - iter 90/100 - loss 0.01608302 - samples/sec: 40.88 - lr: 0.006250\n",
      "2022-01-04 17:44:24,608 epoch 41 - iter 100/100 - loss 0.01636036 - samples/sec: 53.09 - lr: 0.006250\n",
      "2022-01-04 17:44:24,609 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:44:24,610 EPOCH 41 done: loss 0.0164 - lr 0.0062500\n",
      "2022-01-04 17:44:26,922 DEV : loss 0.007137292996048927 - f1-score (micro avg)  0.922\n",
      "Epoch    41: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2022-01-04 17:44:26,956 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:44:26,958 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:44:33,976 epoch 42 - iter 10/100 - loss 0.01118025 - samples/sec: 45.63 - lr: 0.003125\n",
      "2022-01-04 17:44:41,372 epoch 42 - iter 20/100 - loss 0.01357196 - samples/sec: 43.28 - lr: 0.003125\n",
      "2022-01-04 17:44:49,242 epoch 42 - iter 30/100 - loss 0.01288140 - samples/sec: 40.67 - lr: 0.003125\n",
      "2022-01-04 17:44:56,428 epoch 42 - iter 40/100 - loss 0.01326850 - samples/sec: 44.54 - lr: 0.003125\n",
      "2022-01-04 17:45:03,025 epoch 42 - iter 50/100 - loss 0.01429409 - samples/sec: 48.53 - lr: 0.003125\n",
      "2022-01-04 17:45:09,756 epoch 42 - iter 60/100 - loss 0.01398139 - samples/sec: 47.56 - lr: 0.003125\n",
      "2022-01-04 17:45:16,411 epoch 42 - iter 70/100 - loss 0.01389345 - samples/sec: 48.10 - lr: 0.003125\n",
      "2022-01-04 17:45:23,642 epoch 42 - iter 80/100 - loss 0.01379065 - samples/sec: 44.26 - lr: 0.003125\n",
      "2022-01-04 17:45:32,461 epoch 42 - iter 90/100 - loss 0.01397676 - samples/sec: 36.30 - lr: 0.003125\n",
      "2022-01-04 17:45:39,327 epoch 42 - iter 100/100 - loss 0.01501166 - samples/sec: 46.63 - lr: 0.003125\n",
      "2022-01-04 17:45:39,329 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:45:39,330 EPOCH 42 done: loss 0.0150 - lr 0.0031250\n",
      "2022-01-04 17:45:41,644 DEV : loss 0.007201092317700386 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:45:41,683 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:45:41,685 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:45:48,717 epoch 43 - iter 10/100 - loss 0.01529994 - samples/sec: 45.52 - lr: 0.003125\n",
      "2022-01-04 17:45:56,296 epoch 43 - iter 20/100 - loss 0.01501725 - samples/sec: 42.24 - lr: 0.003125\n",
      "2022-01-04 17:46:03,664 epoch 43 - iter 30/100 - loss 0.01420736 - samples/sec: 43.45 - lr: 0.003125\n",
      "2022-01-04 17:46:10,906 epoch 43 - iter 40/100 - loss 0.01368293 - samples/sec: 44.22 - lr: 0.003125\n",
      "2022-01-04 17:46:18,173 epoch 43 - iter 50/100 - loss 0.01423656 - samples/sec: 44.05 - lr: 0.003125\n",
      "2022-01-04 17:46:26,368 epoch 43 - iter 60/100 - loss 0.01475344 - samples/sec: 39.05 - lr: 0.003125\n",
      "2022-01-04 17:46:33,796 epoch 43 - iter 70/100 - loss 0.01529597 - samples/sec: 43.10 - lr: 0.003125\n",
      "2022-01-04 17:46:41,260 epoch 43 - iter 80/100 - loss 0.01656935 - samples/sec: 42.90 - lr: 0.003125\n",
      "2022-01-04 17:46:48,419 epoch 43 - iter 90/100 - loss 0.01582901 - samples/sec: 44.72 - lr: 0.003125\n",
      "2022-01-04 17:46:54,780 epoch 43 - iter 100/100 - loss 0.01515262 - samples/sec: 50.31 - lr: 0.003125\n",
      "2022-01-04 17:46:54,782 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:46:54,783 EPOCH 43 done: loss 0.0152 - lr 0.0031250\n",
      "2022-01-04 17:46:57,613 DEV : loss 0.007406190037727356 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:46:57,654 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:46:57,655 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:47:04,688 epoch 44 - iter 10/100 - loss 0.01523638 - samples/sec: 45.52 - lr: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:47:11,776 epoch 44 - iter 20/100 - loss 0.01399284 - samples/sec: 45.16 - lr: 0.003125\n",
      "2022-01-04 17:47:19,895 epoch 44 - iter 30/100 - loss 0.01223306 - samples/sec: 39.42 - lr: 0.003125\n",
      "2022-01-04 17:47:27,969 epoch 44 - iter 40/100 - loss 0.01118540 - samples/sec: 39.65 - lr: 0.003125\n",
      "2022-01-04 17:47:35,309 epoch 44 - iter 50/100 - loss 0.01228878 - samples/sec: 43.61 - lr: 0.003125\n",
      "2022-01-04 17:47:42,126 epoch 44 - iter 60/100 - loss 0.01374313 - samples/sec: 46.95 - lr: 0.003125\n",
      "2022-01-04 17:47:48,792 epoch 44 - iter 70/100 - loss 0.01337121 - samples/sec: 48.01 - lr: 0.003125\n",
      "2022-01-04 17:47:56,307 epoch 44 - iter 80/100 - loss 0.01475504 - samples/sec: 42.59 - lr: 0.003125\n",
      "2022-01-04 17:48:03,949 epoch 44 - iter 90/100 - loss 0.01512581 - samples/sec: 41.89 - lr: 0.003125\n",
      "2022-01-04 17:48:10,195 epoch 44 - iter 100/100 - loss 0.01463624 - samples/sec: 51.25 - lr: 0.003125\n",
      "2022-01-04 17:48:10,197 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:48:10,198 EPOCH 44 done: loss 0.0146 - lr 0.0031250\n",
      "2022-01-04 17:48:12,471 DEV : loss 0.007402999792248011 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:48:12,502 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:48:12,505 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:48:18,782 epoch 45 - iter 10/100 - loss 0.01705843 - samples/sec: 51.00 - lr: 0.003125\n",
      "2022-01-04 17:48:25,701 epoch 45 - iter 20/100 - loss 0.01704720 - samples/sec: 46.27 - lr: 0.003125\n",
      "2022-01-04 17:48:33,112 epoch 45 - iter 30/100 - loss 0.01571471 - samples/sec: 43.19 - lr: 0.003125\n",
      "2022-01-04 17:48:40,150 epoch 45 - iter 40/100 - loss 0.01515301 - samples/sec: 45.47 - lr: 0.003125\n",
      "2022-01-04 17:48:48,077 epoch 45 - iter 50/100 - loss 0.01480701 - samples/sec: 40.38 - lr: 0.003125\n",
      "2022-01-04 17:48:55,262 epoch 45 - iter 60/100 - loss 0.01458324 - samples/sec: 44.57 - lr: 0.003125\n",
      "2022-01-04 17:49:03,092 epoch 45 - iter 70/100 - loss 0.01464024 - samples/sec: 40.88 - lr: 0.003125\n",
      "2022-01-04 17:49:10,176 epoch 45 - iter 80/100 - loss 0.01466645 - samples/sec: 45.19 - lr: 0.003125\n",
      "2022-01-04 17:49:18,315 epoch 45 - iter 90/100 - loss 0.01464878 - samples/sec: 39.34 - lr: 0.003125\n",
      "2022-01-04 17:49:24,782 epoch 45 - iter 100/100 - loss 0.01433458 - samples/sec: 49.50 - lr: 0.003125\n",
      "2022-01-04 17:49:24,783 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:49:24,784 EPOCH 45 done: loss 0.0143 - lr 0.0031250\n",
      "2022-01-04 17:49:27,089 DEV : loss 0.007245419081300497 - f1-score (micro avg)  0.922\n",
      "Epoch    45: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2022-01-04 17:49:27,118 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:49:27,120 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:49:34,970 epoch 46 - iter 10/100 - loss 0.01407429 - samples/sec: 40.78 - lr: 0.001563\n",
      "2022-01-04 17:49:42,865 epoch 46 - iter 20/100 - loss 0.01399230 - samples/sec: 40.54 - lr: 0.001563\n",
      "2022-01-04 17:49:50,830 epoch 46 - iter 30/100 - loss 0.01506613 - samples/sec: 40.19 - lr: 0.001563\n",
      "2022-01-04 17:49:59,070 epoch 46 - iter 40/100 - loss 0.01349475 - samples/sec: 38.85 - lr: 0.001563\n",
      "2022-01-04 17:50:05,510 epoch 46 - iter 50/100 - loss 0.01276232 - samples/sec: 49.70 - lr: 0.001563\n",
      "2022-01-04 17:50:12,031 epoch 46 - iter 60/100 - loss 0.01351773 - samples/sec: 49.09 - lr: 0.001563\n",
      "2022-01-04 17:50:18,830 epoch 46 - iter 70/100 - loss 0.01397368 - samples/sec: 47.07 - lr: 0.001563\n",
      "2022-01-04 17:50:25,925 epoch 46 - iter 80/100 - loss 0.01400339 - samples/sec: 45.12 - lr: 0.001563\n",
      "2022-01-04 17:50:32,438 epoch 46 - iter 90/100 - loss 0.01395131 - samples/sec: 49.15 - lr: 0.001563\n",
      "2022-01-04 17:50:38,217 epoch 46 - iter 100/100 - loss 0.01430548 - samples/sec: 55.39 - lr: 0.001563\n",
      "2022-01-04 17:50:38,218 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:50:38,219 EPOCH 46 done: loss 0.0143 - lr 0.0015625\n",
      "2022-01-04 17:50:40,399 DEV : loss 0.007381323259323835 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:50:40,435 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:50:40,437 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:50:47,820 epoch 47 - iter 10/100 - loss 0.01733831 - samples/sec: 43.36 - lr: 0.001563\n",
      "2022-01-04 17:50:54,792 epoch 47 - iter 20/100 - loss 0.01291503 - samples/sec: 45.92 - lr: 0.001563\n",
      "2022-01-04 17:51:01,338 epoch 47 - iter 30/100 - loss 0.01295231 - samples/sec: 48.90 - lr: 0.001563\n",
      "2022-01-04 17:51:08,065 epoch 47 - iter 40/100 - loss 0.01339883 - samples/sec: 47.59 - lr: 0.001563\n",
      "2022-01-04 17:51:14,416 epoch 47 - iter 50/100 - loss 0.01303155 - samples/sec: 50.42 - lr: 0.001563\n",
      "2022-01-04 17:51:21,268 epoch 47 - iter 60/100 - loss 0.01369663 - samples/sec: 46.71 - lr: 0.001563\n",
      "2022-01-04 17:51:29,661 epoch 47 - iter 70/100 - loss 0.01330482 - samples/sec: 38.14 - lr: 0.001563\n",
      "2022-01-04 17:51:37,910 epoch 47 - iter 80/100 - loss 0.01349256 - samples/sec: 38.80 - lr: 0.001563\n",
      "2022-01-04 17:51:44,072 epoch 47 - iter 90/100 - loss 0.01466907 - samples/sec: 51.96 - lr: 0.001563\n",
      "2022-01-04 17:51:49,340 epoch 47 - iter 100/100 - loss 0.01448956 - samples/sec: 60.77 - lr: 0.001563\n",
      "2022-01-04 17:51:49,342 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:51:49,343 EPOCH 47 done: loss 0.0145 - lr 0.0015625\n",
      "2022-01-04 17:51:51,523 DEV : loss 0.007379801012575626 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:51:51,560 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:51:51,562 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:51:58,947 epoch 48 - iter 10/100 - loss 0.01732847 - samples/sec: 43.35 - lr: 0.001563\n",
      "2022-01-04 17:52:06,041 epoch 48 - iter 20/100 - loss 0.01469699 - samples/sec: 45.12 - lr: 0.001563\n",
      "2022-01-04 17:52:13,080 epoch 48 - iter 30/100 - loss 0.01412380 - samples/sec: 45.49 - lr: 0.001563\n",
      "2022-01-04 17:52:20,607 epoch 48 - iter 40/100 - loss 0.01400026 - samples/sec: 42.52 - lr: 0.001563\n",
      "2022-01-04 17:52:27,338 epoch 48 - iter 50/100 - loss 0.01382966 - samples/sec: 47.56 - lr: 0.001563\n",
      "2022-01-04 17:52:33,897 epoch 48 - iter 60/100 - loss 0.01486698 - samples/sec: 48.81 - lr: 0.001563\n",
      "2022-01-04 17:52:41,486 epoch 48 - iter 70/100 - loss 0.01433499 - samples/sec: 42.18 - lr: 0.001563\n",
      "2022-01-04 17:52:48,362 epoch 48 - iter 80/100 - loss 0.01409931 - samples/sec: 46.56 - lr: 0.001563\n",
      "2022-01-04 17:52:54,769 epoch 48 - iter 90/100 - loss 0.01454300 - samples/sec: 49.97 - lr: 0.001563\n",
      "2022-01-04 17:53:01,188 epoch 48 - iter 100/100 - loss 0.01451832 - samples/sec: 49.87 - lr: 0.001563\n",
      "2022-01-04 17:53:01,189 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:53:01,190 EPOCH 48 done: loss 0.0145 - lr 0.0015625\n",
      "2022-01-04 17:53:03,838 DEV : loss 0.007316648960113525 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:53:03,868 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:53:03,870 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:53:10,525 epoch 49 - iter 10/100 - loss 0.01698001 - samples/sec: 48.11 - lr: 0.001563\n",
      "2022-01-04 17:53:17,355 epoch 49 - iter 20/100 - loss 0.01500239 - samples/sec: 46.87 - lr: 0.001563\n",
      "2022-01-04 17:53:24,237 epoch 49 - iter 30/100 - loss 0.01349338 - samples/sec: 46.52 - lr: 0.001563\n",
      "2022-01-04 17:53:31,845 epoch 49 - iter 40/100 - loss 0.01367680 - samples/sec: 42.08 - lr: 0.001563\n",
      "2022-01-04 17:53:38,564 epoch 49 - iter 50/100 - loss 0.01448713 - samples/sec: 47.65 - lr: 0.001563\n",
      "2022-01-04 17:53:46,325 epoch 49 - iter 60/100 - loss 0.01499011 - samples/sec: 41.24 - lr: 0.001563\n",
      "2022-01-04 17:53:53,029 epoch 49 - iter 70/100 - loss 0.01420045 - samples/sec: 47.76 - lr: 0.001563\n",
      "2022-01-04 17:54:00,067 epoch 49 - iter 80/100 - loss 0.01372061 - samples/sec: 45.48 - lr: 0.001563\n",
      "2022-01-04 17:54:06,585 epoch 49 - iter 90/100 - loss 0.01466128 - samples/sec: 49.12 - lr: 0.001563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 17:54:12,902 epoch 49 - iter 100/100 - loss 0.01461344 - samples/sec: 50.68 - lr: 0.001563\n",
      "2022-01-04 17:54:12,903 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:54:12,904 EPOCH 49 done: loss 0.0146 - lr 0.0015625\n",
      "2022-01-04 17:54:14,940 DEV : loss 0.007384386379271746 - f1-score (micro avg)  0.922\n",
      "Epoch    49: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2022-01-04 17:54:14,970 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:54:14,972 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:54:21,508 epoch 50 - iter 10/100 - loss 0.01800754 - samples/sec: 48.98 - lr: 0.000781\n",
      "2022-01-04 17:54:28,807 epoch 50 - iter 20/100 - loss 0.01817757 - samples/sec: 43.86 - lr: 0.000781\n",
      "2022-01-04 17:54:36,245 epoch 50 - iter 30/100 - loss 0.01666098 - samples/sec: 43.04 - lr: 0.000781\n",
      "2022-01-04 17:54:43,820 epoch 50 - iter 40/100 - loss 0.01631031 - samples/sec: 42.26 - lr: 0.000781\n",
      "2022-01-04 17:54:50,735 epoch 50 - iter 50/100 - loss 0.01611913 - samples/sec: 46.29 - lr: 0.000781\n",
      "2022-01-04 17:54:57,001 epoch 50 - iter 60/100 - loss 0.01482315 - samples/sec: 51.10 - lr: 0.000781\n",
      "2022-01-04 17:55:04,696 epoch 50 - iter 70/100 - loss 0.01465954 - samples/sec: 41.61 - lr: 0.000781\n",
      "2022-01-04 17:55:10,959 epoch 50 - iter 80/100 - loss 0.01550034 - samples/sec: 51.10 - lr: 0.000781\n",
      "2022-01-04 17:55:18,063 epoch 50 - iter 90/100 - loss 0.01534257 - samples/sec: 45.07 - lr: 0.000781\n",
      "2022-01-04 17:55:24,440 epoch 50 - iter 100/100 - loss 0.01536008 - samples/sec: 50.20 - lr: 0.000781\n",
      "2022-01-04 17:55:24,441 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:55:24,442 EPOCH 50 done: loss 0.0154 - lr 0.0007813\n",
      "2022-01-04 17:55:26,605 DEV : loss 0.007313935551792383 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:55:26,634 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 17:55:26,636 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:55:33,985 epoch 51 - iter 10/100 - loss 0.01327465 - samples/sec: 43.56 - lr: 0.000781\n",
      "2022-01-04 17:55:40,368 epoch 51 - iter 20/100 - loss 0.01380428 - samples/sec: 50.16 - lr: 0.000781\n",
      "2022-01-04 17:55:48,068 epoch 51 - iter 30/100 - loss 0.01491349 - samples/sec: 41.57 - lr: 0.000781\n",
      "2022-01-04 17:55:55,956 epoch 51 - iter 40/100 - loss 0.01541809 - samples/sec: 40.58 - lr: 0.000781\n",
      "2022-01-04 17:56:02,223 epoch 51 - iter 50/100 - loss 0.01552196 - samples/sec: 51.08 - lr: 0.000781\n",
      "2022-01-04 17:56:08,768 epoch 51 - iter 60/100 - loss 0.01651965 - samples/sec: 48.91 - lr: 0.000781\n",
      "2022-01-04 17:56:15,905 epoch 51 - iter 70/100 - loss 0.01656734 - samples/sec: 44.85 - lr: 0.000781\n",
      "2022-01-04 17:56:23,351 epoch 51 - iter 80/100 - loss 0.01580588 - samples/sec: 42.98 - lr: 0.000781\n",
      "2022-01-04 17:56:29,425 epoch 51 - iter 90/100 - loss 0.01539000 - samples/sec: 52.72 - lr: 0.000781\n",
      "2022-01-04 17:56:36,144 epoch 51 - iter 100/100 - loss 0.01527062 - samples/sec: 47.66 - lr: 0.000781\n",
      "2022-01-04 17:56:36,146 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:56:36,147 EPOCH 51 done: loss 0.0153 - lr 0.0007813\n",
      "2022-01-04 17:56:38,267 DEV : loss 0.0073678879998624325 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:56:38,301 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 17:56:38,303 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:56:45,300 epoch 52 - iter 10/100 - loss 0.00925183 - samples/sec: 45.76 - lr: 0.000781\n",
      "2022-01-04 17:56:51,502 epoch 52 - iter 20/100 - loss 0.01392628 - samples/sec: 51.63 - lr: 0.000781\n",
      "2022-01-04 17:56:58,999 epoch 52 - iter 30/100 - loss 0.01317076 - samples/sec: 42.71 - lr: 0.000781\n",
      "2022-01-04 17:57:05,076 epoch 52 - iter 40/100 - loss 0.01448116 - samples/sec: 52.67 - lr: 0.000781\n",
      "2022-01-04 17:57:11,846 epoch 52 - iter 50/100 - loss 0.01385730 - samples/sec: 47.29 - lr: 0.000781\n",
      "2022-01-04 17:57:18,571 epoch 52 - iter 60/100 - loss 0.01506868 - samples/sec: 47.59 - lr: 0.000781\n",
      "2022-01-04 17:57:26,571 epoch 52 - iter 70/100 - loss 0.01488608 - samples/sec: 40.02 - lr: 0.000781\n",
      "2022-01-04 17:57:33,229 epoch 52 - iter 80/100 - loss 0.01511133 - samples/sec: 48.09 - lr: 0.000781\n",
      "2022-01-04 17:57:40,657 epoch 52 - iter 90/100 - loss 0.01506461 - samples/sec: 43.10 - lr: 0.000781\n",
      "2022-01-04 17:57:46,674 epoch 52 - iter 100/100 - loss 0.01511646 - samples/sec: 53.23 - lr: 0.000781\n",
      "2022-01-04 17:57:46,675 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:57:46,676 EPOCH 52 done: loss 0.0151 - lr 0.0007813\n",
      "2022-01-04 17:57:49,244 DEV : loss 0.0072670369409024715 - f1-score (micro avg)  0.922\n",
      "2022-01-04 17:57:49,273 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 17:57:49,275 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:57:56,637 epoch 53 - iter 10/100 - loss 0.01853812 - samples/sec: 43.48 - lr: 0.000781\n",
      "2022-01-04 17:58:03,487 epoch 53 - iter 20/100 - loss 0.01832534 - samples/sec: 46.76 - lr: 0.000781\n",
      "2022-01-04 17:58:10,620 epoch 53 - iter 30/100 - loss 0.01642695 - samples/sec: 44.88 - lr: 0.000781\n",
      "2022-01-04 17:58:17,921 epoch 53 - iter 40/100 - loss 0.01659844 - samples/sec: 43.84 - lr: 0.000781\n",
      "2022-01-04 17:58:25,358 epoch 53 - iter 50/100 - loss 0.01567668 - samples/sec: 43.05 - lr: 0.000781\n",
      "2022-01-04 17:58:33,200 epoch 53 - iter 60/100 - loss 0.01563325 - samples/sec: 40.82 - lr: 0.000781\n",
      "2022-01-04 17:58:40,472 epoch 53 - iter 70/100 - loss 0.01666154 - samples/sec: 44.03 - lr: 0.000781\n",
      "2022-01-04 17:58:48,170 epoch 53 - iter 80/100 - loss 0.01613553 - samples/sec: 41.58 - lr: 0.000781\n",
      "2022-01-04 17:58:54,460 epoch 53 - iter 90/100 - loss 0.01567296 - samples/sec: 50.89 - lr: 0.000781\n",
      "2022-01-04 17:59:00,299 epoch 53 - iter 100/100 - loss 0.01534517 - samples/sec: 54.84 - lr: 0.000781\n",
      "2022-01-04 17:59:00,301 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:59:00,302 EPOCH 53 done: loss 0.0153 - lr 0.0007813\n",
      "2022-01-04 17:59:02,444 DEV : loss 0.007258359808474779 - f1-score (micro avg)  0.922\n",
      "Epoch    53: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2022-01-04 17:59:02,472 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 17:59:02,474 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 17:59:10,321 epoch 54 - iter 10/100 - loss 0.01080649 - samples/sec: 40.80 - lr: 0.000391\n",
      "2022-01-04 17:59:17,428 epoch 54 - iter 20/100 - loss 0.01320622 - samples/sec: 45.05 - lr: 0.000391\n",
      "2022-01-04 17:59:24,559 epoch 54 - iter 30/100 - loss 0.01395938 - samples/sec: 44.89 - lr: 0.000391\n",
      "2022-01-04 17:59:31,485 epoch 54 - iter 40/100 - loss 0.01524214 - samples/sec: 46.22 - lr: 0.000391\n",
      "2022-01-04 17:59:38,340 epoch 54 - iter 50/100 - loss 0.01550708 - samples/sec: 46.69 - lr: 0.000391\n",
      "2022-01-04 17:59:45,079 epoch 54 - iter 60/100 - loss 0.01549670 - samples/sec: 47.50 - lr: 0.000391\n",
      "2022-01-04 17:59:51,271 epoch 54 - iter 70/100 - loss 0.01584590 - samples/sec: 51.71 - lr: 0.000391\n",
      "2022-01-04 17:59:58,035 epoch 54 - iter 80/100 - loss 0.01605573 - samples/sec: 47.34 - lr: 0.000391\n",
      "2022-01-04 18:00:05,928 epoch 54 - iter 90/100 - loss 0.01559956 - samples/sec: 40.56 - lr: 0.000391\n",
      "2022-01-04 18:00:12,107 epoch 54 - iter 100/100 - loss 0.01534388 - samples/sec: 51.81 - lr: 0.000391\n",
      "2022-01-04 18:00:12,109 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:00:12,109 EPOCH 54 done: loss 0.0153 - lr 0.0003906\n",
      "2022-01-04 18:00:14,492 DEV : loss 0.007270035333931446 - f1-score (micro avg)  0.922\n",
      "2022-01-04 18:00:14,535 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 18:00:14,537 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:00:22,126 epoch 55 - iter 10/100 - loss 0.01264078 - samples/sec: 42.19 - lr: 0.000391\n",
      "2022-01-04 18:00:28,967 epoch 55 - iter 20/100 - loss 0.01366587 - samples/sec: 46.80 - lr: 0.000391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 18:00:36,060 epoch 55 - iter 30/100 - loss 0.01322236 - samples/sec: 45.13 - lr: 0.000391\n",
      "2022-01-04 18:00:43,858 epoch 55 - iter 40/100 - loss 0.01305106 - samples/sec: 41.06 - lr: 0.000391\n",
      "2022-01-04 18:00:50,567 epoch 55 - iter 50/100 - loss 0.01385143 - samples/sec: 47.71 - lr: 0.000391\n",
      "2022-01-04 18:00:57,432 epoch 55 - iter 60/100 - loss 0.01440648 - samples/sec: 46.63 - lr: 0.000391\n",
      "2022-01-04 18:01:03,945 epoch 55 - iter 70/100 - loss 0.01538829 - samples/sec: 49.16 - lr: 0.000391\n",
      "2022-01-04 18:01:11,249 epoch 55 - iter 80/100 - loss 0.01545734 - samples/sec: 43.82 - lr: 0.000391\n",
      "2022-01-04 18:01:18,010 epoch 55 - iter 90/100 - loss 0.01524110 - samples/sec: 47.35 - lr: 0.000391\n",
      "2022-01-04 18:01:24,140 epoch 55 - iter 100/100 - loss 0.01452865 - samples/sec: 52.22 - lr: 0.000391\n",
      "2022-01-04 18:01:24,142 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:01:24,143 EPOCH 55 done: loss 0.0145 - lr 0.0003906\n",
      "2022-01-04 18:01:26,334 DEV : loss 0.007279472891241312 - f1-score (micro avg)  0.922\n",
      "2022-01-04 18:01:26,371 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 18:01:26,373 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:01:33,140 epoch 56 - iter 10/100 - loss 0.01341541 - samples/sec: 47.31 - lr: 0.000391\n",
      "2022-01-04 18:01:40,645 epoch 56 - iter 20/100 - loss 0.01357563 - samples/sec: 42.67 - lr: 0.000391\n",
      "2022-01-04 18:01:47,761 epoch 56 - iter 30/100 - loss 0.01544289 - samples/sec: 44.98 - lr: 0.000391\n",
      "2022-01-04 18:01:54,687 epoch 56 - iter 40/100 - loss 0.01579756 - samples/sec: 46.22 - lr: 0.000391\n",
      "2022-01-04 18:02:01,087 epoch 56 - iter 50/100 - loss 0.01608312 - samples/sec: 50.03 - lr: 0.000391\n",
      "2022-01-04 18:02:08,157 epoch 56 - iter 60/100 - loss 0.01567771 - samples/sec: 45.29 - lr: 0.000391\n",
      "2022-01-04 18:02:16,469 epoch 56 - iter 70/100 - loss 0.01597711 - samples/sec: 38.51 - lr: 0.000391\n",
      "2022-01-04 18:02:24,134 epoch 56 - iter 80/100 - loss 0.01586210 - samples/sec: 41.76 - lr: 0.000391\n",
      "2022-01-04 18:02:30,853 epoch 56 - iter 90/100 - loss 0.01596889 - samples/sec: 47.65 - lr: 0.000391\n",
      "2022-01-04 18:02:38,723 epoch 56 - iter 100/100 - loss 0.01543710 - samples/sec: 40.68 - lr: 0.000391\n",
      "2022-01-04 18:02:38,725 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:02:38,726 EPOCH 56 done: loss 0.0154 - lr 0.0003906\n",
      "2022-01-04 18:02:40,846 DEV : loss 0.0072340150363743305 - f1-score (micro avg)  0.922\n",
      "2022-01-04 18:02:40,883 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 18:02:40,885 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:02:47,339 epoch 57 - iter 10/100 - loss 0.02143501 - samples/sec: 49.60 - lr: 0.000391\n",
      "2022-01-04 18:02:53,870 epoch 57 - iter 20/100 - loss 0.02167460 - samples/sec: 49.04 - lr: 0.000391\n",
      "2022-01-04 18:03:00,899 epoch 57 - iter 30/100 - loss 0.01862283 - samples/sec: 45.54 - lr: 0.000391\n",
      "2022-01-04 18:03:07,817 epoch 57 - iter 40/100 - loss 0.01719312 - samples/sec: 46.27 - lr: 0.000391\n",
      "2022-01-04 18:03:15,023 epoch 57 - iter 50/100 - loss 0.01528351 - samples/sec: 44.43 - lr: 0.000391\n",
      "2022-01-04 18:03:22,477 epoch 57 - iter 60/100 - loss 0.01536692 - samples/sec: 42.95 - lr: 0.000391\n",
      "2022-01-04 18:03:30,019 epoch 57 - iter 70/100 - loss 0.01486837 - samples/sec: 42.44 - lr: 0.000391\n",
      "2022-01-04 18:03:36,656 epoch 57 - iter 80/100 - loss 0.01570223 - samples/sec: 48.23 - lr: 0.000391\n",
      "2022-01-04 18:03:43,144 epoch 57 - iter 90/100 - loss 0.01592177 - samples/sec: 49.35 - lr: 0.000391\n",
      "2022-01-04 18:03:49,993 epoch 57 - iter 100/100 - loss 0.01574858 - samples/sec: 46.73 - lr: 0.000391\n",
      "2022-01-04 18:03:49,995 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:03:49,996 EPOCH 57 done: loss 0.0157 - lr 0.0003906\n",
      "2022-01-04 18:03:52,515 DEV : loss 0.007260101847350597 - f1-score (micro avg)  0.922\n",
      "Epoch    57: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2022-01-04 18:03:52,547 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 18:03:52,549 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:03:59,691 epoch 58 - iter 10/100 - loss 0.01404585 - samples/sec: 44.82 - lr: 0.000195\n",
      "2022-01-04 18:04:05,858 epoch 58 - iter 20/100 - loss 0.01557971 - samples/sec: 51.91 - lr: 0.000195\n",
      "2022-01-04 18:04:12,704 epoch 58 - iter 30/100 - loss 0.01481735 - samples/sec: 46.77 - lr: 0.000195\n",
      "2022-01-04 18:04:19,793 epoch 58 - iter 40/100 - loss 0.01364690 - samples/sec: 45.16 - lr: 0.000195\n",
      "2022-01-04 18:04:26,083 epoch 58 - iter 50/100 - loss 0.01458340 - samples/sec: 50.89 - lr: 0.000195\n",
      "2022-01-04 18:04:32,960 epoch 58 - iter 60/100 - loss 0.01392396 - samples/sec: 46.54 - lr: 0.000195\n",
      "2022-01-04 18:04:39,378 epoch 58 - iter 70/100 - loss 0.01406361 - samples/sec: 49.89 - lr: 0.000195\n",
      "2022-01-04 18:04:47,325 epoch 58 - iter 80/100 - loss 0.01372047 - samples/sec: 40.27 - lr: 0.000195\n",
      "2022-01-04 18:04:53,979 epoch 58 - iter 90/100 - loss 0.01337717 - samples/sec: 48.12 - lr: 0.000195\n",
      "2022-01-04 18:05:00,665 epoch 58 - iter 100/100 - loss 0.01370486 - samples/sec: 47.88 - lr: 0.000195\n",
      "2022-01-04 18:05:00,667 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:05:00,668 EPOCH 58 done: loss 0.0137 - lr 0.0001953\n",
      "2022-01-04 18:05:02,909 DEV : loss 0.00726687116548419 - f1-score (micro avg)  0.922\n",
      "2022-01-04 18:05:02,954 BAD EPOCHS (no improvement): 1\n",
      "2022-01-04 18:05:02,955 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:05:09,771 epoch 59 - iter 10/100 - loss 0.01572304 - samples/sec: 46.96 - lr: 0.000195\n",
      "2022-01-04 18:05:16,973 epoch 59 - iter 20/100 - loss 0.01744368 - samples/sec: 44.45 - lr: 0.000195\n",
      "2022-01-04 18:05:24,404 epoch 59 - iter 30/100 - loss 0.01790431 - samples/sec: 43.07 - lr: 0.000195\n",
      "2022-01-04 18:05:30,743 epoch 59 - iter 40/100 - loss 0.01645381 - samples/sec: 50.51 - lr: 0.000195\n",
      "2022-01-04 18:05:38,275 epoch 59 - iter 50/100 - loss 0.01581684 - samples/sec: 42.52 - lr: 0.000195\n",
      "2022-01-04 18:05:45,104 epoch 59 - iter 60/100 - loss 0.01588692 - samples/sec: 46.89 - lr: 0.000195\n",
      "2022-01-04 18:05:51,508 epoch 59 - iter 70/100 - loss 0.01536298 - samples/sec: 50.00 - lr: 0.000195\n",
      "2022-01-04 18:05:58,693 epoch 59 - iter 80/100 - loss 0.01497552 - samples/sec: 44.55 - lr: 0.000195\n",
      "2022-01-04 18:06:05,146 epoch 59 - iter 90/100 - loss 0.01476271 - samples/sec: 49.62 - lr: 0.000195\n",
      "2022-01-04 18:06:11,346 epoch 59 - iter 100/100 - loss 0.01412671 - samples/sec: 51.64 - lr: 0.000195\n",
      "2022-01-04 18:06:11,347 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:06:11,348 EPOCH 59 done: loss 0.0141 - lr 0.0001953\n",
      "2022-01-04 18:06:13,573 DEV : loss 0.007259090896695852 - f1-score (micro avg)  0.922\n",
      "2022-01-04 18:06:13,629 BAD EPOCHS (no improvement): 2\n",
      "2022-01-04 18:06:13,631 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:06:21,083 epoch 60 - iter 10/100 - loss 0.01887840 - samples/sec: 42.96 - lr: 0.000195\n",
      "2022-01-04 18:06:28,270 epoch 60 - iter 20/100 - loss 0.01683616 - samples/sec: 44.54 - lr: 0.000195\n",
      "2022-01-04 18:06:34,283 epoch 60 - iter 30/100 - loss 0.01695386 - samples/sec: 53.23 - lr: 0.000195\n",
      "2022-01-04 18:06:40,856 epoch 60 - iter 40/100 - loss 0.01825538 - samples/sec: 48.71 - lr: 0.000195\n",
      "2022-01-04 18:06:47,990 epoch 60 - iter 50/100 - loss 0.01717997 - samples/sec: 44.87 - lr: 0.000195\n",
      "2022-01-04 18:06:55,505 epoch 60 - iter 60/100 - loss 0.01680927 - samples/sec: 42.60 - lr: 0.000195\n",
      "2022-01-04 18:07:02,778 epoch 60 - iter 70/100 - loss 0.01663685 - samples/sec: 44.00 - lr: 0.000195\n",
      "2022-01-04 18:07:10,119 epoch 60 - iter 80/100 - loss 0.01610828 - samples/sec: 43.61 - lr: 0.000195\n",
      "2022-01-04 18:07:16,737 epoch 60 - iter 90/100 - loss 0.01587397 - samples/sec: 48.37 - lr: 0.000195\n",
      "2022-01-04 18:07:23,285 epoch 60 - iter 100/100 - loss 0.01562100 - samples/sec: 48.89 - lr: 0.000195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 18:07:23,287 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:07:23,288 EPOCH 60 done: loss 0.0156 - lr 0.0001953\n",
      "2022-01-04 18:07:25,492 DEV : loss 0.007241406477987766 - f1-score (micro avg)  0.922\n",
      "2022-01-04 18:07:25,521 BAD EPOCHS (no improvement): 3\n",
      "2022-01-04 18:07:25,523 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:07:32,247 epoch 61 - iter 10/100 - loss 0.00803018 - samples/sec: 47.61 - lr: 0.000195\n",
      "2022-01-04 18:07:39,128 epoch 61 - iter 20/100 - loss 0.01498504 - samples/sec: 46.53 - lr: 0.000195\n",
      "2022-01-04 18:07:46,972 epoch 61 - iter 30/100 - loss 0.01395941 - samples/sec: 40.81 - lr: 0.000195\n",
      "2022-01-04 18:07:53,005 epoch 61 - iter 40/100 - loss 0.01563273 - samples/sec: 53.06 - lr: 0.000195\n",
      "2022-01-04 18:07:59,289 epoch 61 - iter 50/100 - loss 0.01519114 - samples/sec: 50.96 - lr: 0.000195\n",
      "2022-01-04 18:08:06,254 epoch 61 - iter 60/100 - loss 0.01489978 - samples/sec: 45.97 - lr: 0.000195\n",
      "2022-01-04 18:08:13,058 epoch 61 - iter 70/100 - loss 0.01586164 - samples/sec: 47.05 - lr: 0.000195\n",
      "2022-01-04 18:08:20,576 epoch 61 - iter 80/100 - loss 0.01594261 - samples/sec: 42.58 - lr: 0.000195\n",
      "2022-01-04 18:08:28,249 epoch 61 - iter 90/100 - loss 0.01563440 - samples/sec: 41.71 - lr: 0.000195\n",
      "2022-01-04 18:08:35,234 epoch 61 - iter 100/100 - loss 0.01530914 - samples/sec: 45.85 - lr: 0.000195\n",
      "2022-01-04 18:08:35,235 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:08:35,236 EPOCH 61 done: loss 0.0153 - lr 0.0001953\n",
      "2022-01-04 18:08:37,434 DEV : loss 0.007224260829389095 - f1-score (micro avg)  0.922\n",
      "Epoch    61: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2022-01-04 18:08:37,463 BAD EPOCHS (no improvement): 4\n",
      "2022-01-04 18:08:37,465 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:08:37,466 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:08:37,467 learning rate too small - quitting training!\n",
      "2022-01-04 18:08:37,469 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:08:39,266 ----------------------------------------------------------------------------------------------------\n",
      "2022-01-04 18:08:39,267 loading file data\\flairfirstpartmodel\\best-model.pt\n",
      "2022-01-04 18:08:42,048 0.8594\t0.6471\t0.7383\t0.5978\n",
      "2022-01-04 18:08:42,050 \n",
      "Results:\n",
      "- F-score (micro) 0.7383\n",
      "- F-score (macro) 0.4406\n",
      "- Accuracy 0.5978\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    U-PERSON     0.9464    0.6386    0.7626        83\n",
      "      PERSON     0.3333    1.0000    0.5000         1\n",
      "    L-PERSON     0.3333    1.0000    0.5000         1\n",
      "           -     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.8594    0.6471    0.7383        85\n",
      "   macro avg     0.4033    0.6596    0.4406        85\n",
      "weighted avg     0.9320    0.6471    0.7564        85\n",
      " samples avg     0.5978    0.5978    0.5978        85\n",
      "\n",
      "2022-01-04 18:08:42,051 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.7382550335570471,\n",
       " 'dev_score_history': [0.48125000000000007,\n",
       "  0.7474226804123711,\n",
       "  0.608955223880597,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  0.8605769230769231,\n",
       "  0.8819277108433734,\n",
       "  0.8535353535353536,\n",
       "  0.9148418491484185,\n",
       "  0.6762589928057553,\n",
       "  0.9112709832134293,\n",
       "  0.8341708542713568,\n",
       "  0.8833746898263027,\n",
       "  0.9297820823244553,\n",
       "  0.9144254278728606,\n",
       "  0.911764705882353,\n",
       "  0.9170731707317074,\n",
       "  0.928395061728395,\n",
       "  0.9257425742574258,\n",
       "  0.9203980099502488,\n",
       "  0.9287469287469287,\n",
       "  0.9290953545232273,\n",
       "  0.928395061728395,\n",
       "  0.9310344827586207,\n",
       "  0.9219512195121952,\n",
       "  0.9264705882352942,\n",
       "  0.9219512195121952,\n",
       "  0.9290953545232273,\n",
       "  0.9290953545232273,\n",
       "  0.9219512195121952,\n",
       "  0.9290953545232273,\n",
       "  0.9313725490196079,\n",
       "  0.9313725490196079,\n",
       "  0.9313725490196079,\n",
       "  0.9313725490196079,\n",
       "  0.9313725490196079,\n",
       "  0.9313725490196079,\n",
       "  0.9245742092457421,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952,\n",
       "  0.9219512195121952],\n",
       " 'train_loss_history': [0.09811137046648168,\n",
       "  0.03487915472213194,\n",
       "  0.031257850957727734,\n",
       "  0.02946941119000766,\n",
       "  0.027212654981642694,\n",
       "  0.024858810013810947,\n",
       "  0.025551130160767984,\n",
       "  0.024410093401218524,\n",
       "  0.023444577061483677,\n",
       "  0.0224398907835943,\n",
       "  0.023228991932723632,\n",
       "  0.02229850491878241,\n",
       "  0.021866644145132483,\n",
       "  0.01959888163493489,\n",
       "  0.019600222409480558,\n",
       "  0.01771854821616881,\n",
       "  0.01799929131699364,\n",
       "  0.018039262258168483,\n",
       "  0.016429692875570976,\n",
       "  0.017072881550075688,\n",
       "  0.016779060541988505,\n",
       "  0.017071872641820744,\n",
       "  0.017171890073928074,\n",
       "  0.016276561138214376,\n",
       "  0.015556108980564044,\n",
       "  0.015622799990715456,\n",
       "  0.01525693180151105,\n",
       "  0.016229459898024733,\n",
       "  0.015520310429485939,\n",
       "  0.01556983186051592,\n",
       "  0.017041495629791306,\n",
       "  0.015308327751362984,\n",
       "  0.015334145938535562,\n",
       "  0.015303732306690075,\n",
       "  0.015273026971200856,\n",
       "  0.014982621131721644,\n",
       "  0.014509287396009924,\n",
       "  0.014949806037238732,\n",
       "  0.014716031716555876,\n",
       "  0.015297701952108438,\n",
       "  0.016360362145816973,\n",
       "  0.015011659118438582,\n",
       "  0.015152623544813639,\n",
       "  0.014636243576590697,\n",
       "  0.014334579121070353,\n",
       "  0.014305476266956866,\n",
       "  0.014489564874461626,\n",
       "  0.014518321361394965,\n",
       "  0.014613438373829682,\n",
       "  0.015360079289895997,\n",
       "  0.015270621395330372,\n",
       "  0.015116463035564128,\n",
       "  0.015345172451616613,\n",
       "  0.015343881752039207,\n",
       "  0.014528654823225648,\n",
       "  0.015437095421331547,\n",
       "  0.01574858039507023,\n",
       "  0.013704861652426948,\n",
       "  0.014126709124617868,\n",
       "  0.015620999795289626,\n",
       "  0.01530913947160534],\n",
       " 'dev_loss_history': [tensor(0.0318),\n",
       "  tensor(0.0226),\n",
       "  tensor(0.0292),\n",
       "  tensor(0.0158),\n",
       "  tensor(0.0151),\n",
       "  tensor(0.0132),\n",
       "  tensor(0.0119),\n",
       "  tensor(0.0146),\n",
       "  tensor(0.0105),\n",
       "  tensor(0.0188),\n",
       "  tensor(0.0094),\n",
       "  tensor(0.0119),\n",
       "  tensor(0.0111),\n",
       "  tensor(0.0086),\n",
       "  tensor(0.0089),\n",
       "  tensor(0.0092),\n",
       "  tensor(0.0084),\n",
       "  tensor(0.0092),\n",
       "  tensor(0.0088),\n",
       "  tensor(0.0088),\n",
       "  tensor(0.0082),\n",
       "  tensor(0.0076),\n",
       "  tensor(0.0083),\n",
       "  tensor(0.0084),\n",
       "  tensor(0.0076),\n",
       "  tensor(0.0079),\n",
       "  tensor(0.0078),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0076),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0076),\n",
       "  tensor(0.0077),\n",
       "  tensor(0.0076),\n",
       "  tensor(0.0075),\n",
       "  tensor(0.0075),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0072),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0072),\n",
       "  tensor(0.0071),\n",
       "  tensor(0.0072),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0072),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0074),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0072),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0073),\n",
       "  tensor(0.0072),\n",
       "  tensor(0.0072)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "trainer : ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "    \n",
    "trainer.train('data/flairfirstpartmodel',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4883322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
